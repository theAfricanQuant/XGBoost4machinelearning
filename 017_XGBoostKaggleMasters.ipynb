{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88e4af41-de36-4683-8d5b-bd53136a8e2d",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;\">Kaggle Masters</h1>\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In this notebook, you will acquire valuable insights and techniques from Kaggle Masters who have utilized XGBoost to secure victories in Kaggle contests. While we won't be participating in a Kaggle contest ourselves, the competencies you develop here are broadly applicable to enhancing your machine learning models. You'll particularly understand the importance of an extra hold-out set, discover the process of feature engineering by creating new data columns through mean encoding, learn the implementation of `VotingClassifier` and `VotingRegressor` for crafting non-correlated machine learning ensembles, and explore the benefits of stacking a final model.\n",
    "\n",
    "This notebook will focus on the following key areas:\n",
    "\n",
    "- Delving into Kaggle competitions\n",
    "- Crafting new data columns through feature engineering\n",
    "- Developing non-correlated ensembles\n",
    "- Stacking final models\n",
    "\n",
    "### Kaggle Competitions\n",
    "\n",
    "This section delves into the realm of Kaggle competitions, focusing on their historical context, structural aspects, and the crucial role of hold-out/test sets, distinct from validation/test sets.\n",
    "\n",
    "Kaggle competitions serve as a battleground for machine learning practitioners, challenging them to outperform peers in predictive accuracy to win monetary rewards. A standout in these competitions has been XGBoost, a machine learning algorithm that gained fame for its consistent victories, often in conjunction with or against deep learning models like neural networks. Its winning streak is well-documented, with a list of victorious Kaggle competitions available on the Distributed (Deep) Machine Learning Community's GitHub page (https://github.com/dmlc/xgboost/tree/master/demo#machine-learning-challenge-winning-solutions) and a broader compilation on Kaggle (https://www.kaggle.com/sudalairajkumar/winning-solutions-of-kaggle-competitions).\n",
    "\n",
    "XGBoost's entry into the spotlight was marked by its impressive performance in the 2014 Higgs Boson Machine Learning Challenge, where it rapidly climbed the leaderboard. Between 2014 and 2018, XGBoost was particularly dominant in competitions involving tabular data, which is structured in rows and columns, unlike unstructured data such as images or text that typically favor neural networks. However, with the 2017 advent of LightGBM by Microsoft, a fast and efficient gradient boosting alternative, XGBoost found a worthy competitor, especially in handling tabular data. For those interested in learning more about LightGBM, the introductory paper \"LightGBM: A Highly Efficient Gradient Boosting Decision Tree\" (https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree.pdf) is an excellent resource.\n",
    "\n",
    "However, merely implementing powerful algorithms like XGBoost or LightGBM is not sufficient in the competitive landscape of Kaggle. Nor is fine-tuning model hyperparameters the sole answer. A holistic approach that includes individual model predictions, innovative data engineering, and the strategic combination of optimal models is key to achieving higher scores and securing wins in these competitions.\n",
    "\n",
    "Understanding the structure of Kaggle competitions is crucial for grasping why certain strategies, like building non-correlated ensembles and stacking models, are prevalent and effective. This knowledge is not only academically enriching but also practical, especially for those considering participating in Kaggle competitions in the future.\n",
    "\n",
    "**Key Insights:**\n",
    "\n",
    "1. **Kaggle's Structure and Recommendations:** Kaggle competitions are organized on their website, providing a platform for machine learning enthusiasts to test and improve their skills. For those transitioning from basic to more advanced levels in machine learning, Kaggle suggests starting with specific competitions like the \"Housing Prices: Advanced Regression Techniques\" (https://www.kaggle.com/c/house-prices-advanced-regression-techniques). Such competitions, often without cash prizes, focus on deepening knowledge and honing skills.\n",
    "\n",
    "2. **Historical Context of XGBoost's Success:** A notable aspect of Kaggle competitions is the success stories of various algorithms. For instance, XGBoost, a highly efficient algorithm, has been a frequent winner in these competitions. The 2015 Avito Context Ad Clicks competition (https://www.kaggle.com/c/avito-context-ad-clicks/overview), won by XGBoost user Owen Zhang, is one such example. The widespread use of XGBoost in Kaggle competitions, especially before the publication of Tianqi Chen's influential paper \"XGBoost: A Scalable Tree Boosting System\" in 2016 (https://arxiv.org/pdf/1603.02754.pdf), showcases its early adoption and effectiveness in the field.\n",
    "\n",
    "Understanding these aspects of Kaggle competitions can boost your confidence and readiness to engage in these challenges, whether for learning or competing at a higher level.\n",
    "\n",
    "This comprehensive overview provides a detailed look into the structure and nuances of Kaggle competitions, emphasizing the importance of different datasets, the process of model testing, and how these practices relate to real-world machine learning applications.\n",
    "\n",
    "**Key Elements of Kaggle Competitions:**\n",
    "\n",
    "1. **Competition Structure:** The Kaggle competition page typically includes several sections:\n",
    "   - **Data:** Access to competition datasets.\n",
    "   - **Notebooks:** A repository for shared solutions and starter notebooks.\n",
    "   - **Discussion:** A forum for questions and answers.\n",
    "   - **Leaderboard:** Displays top scores.\n",
    "   - **Rules:** Details the competition's guidelines.\n",
    "   - **Late Submission:** Indicates ongoing submissions post-competition, a common Kaggle policy.\n",
    "\n",
    "2. **Joining and Downloading Data:** To participate, you must sign up for a free Kaggle account. The data is generally divided into `training.csv` for model building, and `test.csv` for model scoring. Initial scores are based on a public leaderboard, with a final model evaluated against a private test set at the competition's conclusion.\n",
    "\n",
    "3. **Hold-Out Sets in Kaggle vs. General Practice:**\n",
    "   - In both Kaggle and general machine learning practices, datasets are split into training and test sets. However, in Kaggle, the test set remains unseen to ensure fair competition.\n",
    "   - **Training Set (`training.csv`):** Used for training and internal scoring, often split further into training and validation sets.\n",
    "   - **Test Set (`test.csv`):** A separate hold-out set, used only for final model evaluation. Its purpose is to preserve competition integrity.\n",
    "\n",
    "4. **Overfitting Risks and Real-World Relevance:** Overfitting to the test set, especially in pursuit of marginal leaderboard gains, is a common pitfall. A model that excels on training data but fails on unseen data is of little practical value. The real test of a model's efficacy is its performance on new, unknown data.\n",
    "\n",
    "5. **Validating and Testing Models:**\n",
    "   - **Initial Split:** Divide data into a training set and a hold-out set, avoiding any peek at the hold-out set.\n",
    "   - **Further Split or Cross-Validation:** Use the training set for model fitting and validation, iteratively improving performance.\n",
    "   - **Final Test:** Evaluate the final model on the hold-out set. If results are unsatisfactory, revisit model adjustments but refrain from using the hold-out set for further tuning.\n",
    "\n",
    "6. **Kaggle's Unique Testing Approach:** Kaggle competitions often have a dual test set structure â€“ a public set for ongoing scoring and a private set revealed at competition's end. Success in Kaggle requires excelling on the private test set.\n",
    "\n",
    "7. **Impact on Machine Learning Practices:** The precision and rigor demanded in Kaggle competitions have spurred innovative techniques in machine learning. Understanding and applying these techniques can lead to the development of more robust models and a deeper comprehension of the field.\n",
    "\n",
    "In summary, Kaggle competitions offer a structured and competitive environment for machine learning practitioners. They emphasize the importance of proper data handling, the perils of overfitting, and the significance of model validation and testing, paralleling real-world machine learning challenges and solutions.\n",
    "\n",
    "### Feature Engineering\n",
    "\n",
    "Feature engineering is a pivotal aspect of data science and machine learning, often consuming significant time and effort. In this section, we'll delve into using pandas to create new data columns through feature engineering.\n",
    "\n",
    "**Understanding Feature Engineering:**\n",
    "Feature engineering is the practice of generating new data columns from existing ones. The effectiveness of machine learning models heavily depends on the quality and robustness of the data they are trained on. When the available data is lacking, feature engineering becomes essential to enhance the dataset.\n",
    "\n",
    "The aim is not just to decide whether to engage in feature engineering, but to determine the extent to which it should be applied. This process often involves creatively extracting and combining information from existing columns to form new, informative features.\n",
    "\n",
    "**Application in Uber and Lyft Data:**\n",
    "For instance, consider a dataset for predicting cab fares for services like Uber and Lyft. Feature engineering might involve creating new columns such as:\n",
    "- **Distance:** Calculating the distance between the pickup and drop-off points.\n",
    "- **Time of Day:** Extracting the part of the day (morning, afternoon, evening) from the timestamp, as fares might vary with time.\n",
    "- **Day of the Week:** Identifying the day of the week, since weekends or specific weekdays might have different pricing dynamics.\n",
    "- **Weather Conditions:** Integrating weather data, as adverse weather might affect fare prices.\n",
    "\n",
    "This kind of dataset, along with many others, is available on Kaggle, such as the Uber and Lyft cab prices dataset (https://www.kaggle.com/ravi72munde/uber-lyft-cab-prices). By creatively manipulating and enriching this data, we can build more accurate and reliable predictive models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24255a7f-1183-4202-ad86-d0c5e0f6a31e",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# URL of the CSV file\n",
    "url = 'https://media.githubusercontent.com/media/theAfricanQuant/XGBoost4machinelearning/main/data/cab_rides.csv'\n",
    "\n",
    "# Reading the CSV file directly from the URL\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Path for the data directory\n",
    "data_dir = Path('data')\n",
    "\n",
    "# Create a data folder if it doesn't exist\n",
    "if not data_dir.exists():\n",
    "    data_dir.mkdir()\n",
    "\n",
    "# File path for saving, using the Path object\n",
    "file_path = data_dir / 'cab_rides.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(file_path, index=False)\n",
    "```\n",
    "\n",
    "In this code:\n",
    "- `Path('data')` creates a `Path` object for the 'data' directory.\n",
    "- `data_dir.mkdir()` is used instead of `os.makedirs('data')`.\n",
    "- `file_path = data_dir / 'cab_rides.csv'` leverages `Path` object's `/` operator to concatenate paths in a platform-independent manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bac5998a-9665-4c1e-8df7-9aadc934d799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "from helper_file import *\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b978b459-dbd5-41c6-ada8-5bf8d33398ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the CSV file\n",
    "url = 'https://media.githubusercontent.com/media/theAfricanQuant/XGBoost4machinelearning/main/data/cab_rides.csv'\n",
    "\n",
    "# Reading the CSV file directly from the URL\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Path for the data directory\n",
    "data_dir = Path('data')\n",
    "\n",
    "# Create a data folder if it doesn't exist\n",
    "if not data_dir.exists():\n",
    "    data_dir.mkdir()\n",
    "\n",
    "# File path for saving, using the Path object\n",
    "file_path = data_dir / 'cab_rides.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8407f77f-d039-4bd2-a18c-a8889a3483ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>cab_type</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>destination</th>\n",
       "      <th>source</th>\n",
       "      <th>price</th>\n",
       "      <th>surge_multiplier</th>\n",
       "      <th>id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9415</th>\n",
       "      <td>2.32</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1544727314997</td>\n",
       "      <td>Haymarket Square</td>\n",
       "      <td>Back Bay</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12d1d3df-a56a-4eb3-8701-934b8a124a2b</td>\n",
       "      <td>6f72dfc5-27f1-42e8-84db-ccc7a75f6969</td>\n",
       "      <td>UberXL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6377</th>\n",
       "      <td>1.45</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1543887779314</td>\n",
       "      <td>Back Bay</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>13.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6935e9e9-1441-43c2-b12b-bde33ffeed6d</td>\n",
       "      <td>lyft_plus</td>\n",
       "      <td>Lyft XL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8019</th>\n",
       "      <td>2.42</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1544408018848</td>\n",
       "      <td>Beacon Hill</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>dc4370ad-2fcd-4b1c-ac8e-3852ede9e2ce</td>\n",
       "      <td>lyft</td>\n",
       "      <td>Lyft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7754</th>\n",
       "      <td>1.28</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1543428682509</td>\n",
       "      <td>Haymarket Square</td>\n",
       "      <td>Financial District</td>\n",
       "      <td>16.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>f8d74ea0-9b61-41ae-87e8-f98cad871d5d</td>\n",
       "      <td>lyft_lux</td>\n",
       "      <td>Lux Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4961</th>\n",
       "      <td>1.50</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1544896513984</td>\n",
       "      <td>Back Bay</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21a5aa7e-1fa4-45a9-a6b9-69febaee879c</td>\n",
       "      <td>9a0e7b09-b92b-4c41-9779-2ad22b4d779d</td>\n",
       "      <td>WAV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      distance cab_type     time_stamp       destination              source  \\\n",
       "9415      2.32     Uber  1544727314997  Haymarket Square            Back Bay   \n",
       "6377      1.45     Lyft  1543887779314          Back Bay              Fenway   \n",
       "8019      2.42     Lyft  1544408018848       Beacon Hill              Fenway   \n",
       "7754      1.28     Lyft  1543428682509  Haymarket Square  Financial District   \n",
       "4961      1.50     Uber  1544896513984          Back Bay              Fenway   \n",
       "\n",
       "      price  surge_multiplier                                    id  \\\n",
       "9415   15.0               1.0  12d1d3df-a56a-4eb3-8701-934b8a124a2b   \n",
       "6377   13.5               1.0  6935e9e9-1441-43c2-b12b-bde33ffeed6d   \n",
       "8019    9.0               1.0  dc4370ad-2fcd-4b1c-ac8e-3852ede9e2ce   \n",
       "7754   16.5               1.0  f8d74ea0-9b61-41ae-87e8-f98cad871d5d   \n",
       "4961    7.0               1.0  21a5aa7e-1fa4-45a9-a6b9-69febaee879c   \n",
       "\n",
       "                                product_id       name  \n",
       "9415  6f72dfc5-27f1-42e8-84db-ccc7a75f6969     UberXL  \n",
       "6377                             lyft_plus    Lyft XL  \n",
       "8019                                  lyft       Lyft  \n",
       "7754                              lyft_lux  Lux Black  \n",
       "4961  9a0e7b09-b92b-4c41-9779-2ad22b4d779d        WAV  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(file_path, nrows=10000)\n",
    "df.sample(n=5, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "871fb379-1acd-45b1-bb27-c311f5834437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   distance          10000 non-null  float64\n",
      " 1   cab_type          10000 non-null  object \n",
      " 2   time_stamp        10000 non-null  int64  \n",
      " 3   destination       10000 non-null  object \n",
      " 4   source            10000 non-null  object \n",
      " 5   price             9227 non-null   float64\n",
      " 6   surge_multiplier  10000 non-null  float64\n",
      " 7   id                10000 non-null  object \n",
      " 8   product_id        10000 non-null  object \n",
      " 9   name              10000 non-null  object \n",
      "dtypes: float64(3), int64(1), object(6)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80fdf23-193b-45c2-a276-53e02bd49407",
   "metadata": {},
   "source": [
    "From the output seen above, we can notice that the `price` column has null values, since the number of Non-Null is less than 10,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07822cff-e124-47e4-a81f-9a4f1c1d9522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>cab_type</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>destination</th>\n",
       "      <th>source</th>\n",
       "      <th>price</th>\n",
       "      <th>surge_multiplier</th>\n",
       "      <th>id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.11</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1543673584211</td>\n",
       "      <td>West End</td>\n",
       "      <td>North End</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fa5fb705-03a0-4eb9-82d9-7fe80872f754</td>\n",
       "      <td>8cf7e821-f0d3-49c6-8eba-e679c0ebcf6a</td>\n",
       "      <td>Taxi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2.48</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1543794776318</td>\n",
       "      <td>South Station</td>\n",
       "      <td>Beacon Hill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>eee70d94-6706-4b95-a8ce-0e34f0fa8f37</td>\n",
       "      <td>8cf7e821-f0d3-49c6-8eba-e679c0ebcf6a</td>\n",
       "      <td>Taxi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2.94</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1543523885298</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>North Station</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7f47ff53-7cf2-4a6a-8049-83c90e042593</td>\n",
       "      <td>8cf7e821-f0d3-49c6-8eba-e679c0ebcf6a</td>\n",
       "      <td>Taxi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.16</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1544731816318</td>\n",
       "      <td>West End</td>\n",
       "      <td>North End</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43abdbe4-ab9e-4f39-afdc-31cfa375dc25</td>\n",
       "      <td>8cf7e821-f0d3-49c6-8eba-e679c0ebcf6a</td>\n",
       "      <td>Taxi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2.67</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1543583283653</td>\n",
       "      <td>Beacon Hill</td>\n",
       "      <td>North End</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80db1c49-9d51-4575-a4f4-1ec23b4d3e31</td>\n",
       "      <td>8cf7e821-f0d3-49c6-8eba-e679c0ebcf6a</td>\n",
       "      <td>Taxi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9949</th>\n",
       "      <td>1.08</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1543272429665</td>\n",
       "      <td>North End</td>\n",
       "      <td>North Station</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74fffcba-da67-42d1-b585-13d546a125be</td>\n",
       "      <td>8cf7e821-f0d3-49c6-8eba-e679c0ebcf6a</td>\n",
       "      <td>Taxi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9953</th>\n",
       "      <td>2.46</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1545045010035</td>\n",
       "      <td>Beacon Hill</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18c2e91d-d594-4a22-9be7-0a5829efa4bf</td>\n",
       "      <td>8cf7e821-f0d3-49c6-8eba-e679c0ebcf6a</td>\n",
       "      <td>Taxi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9965</th>\n",
       "      <td>2.58</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1544815809335</td>\n",
       "      <td>Beacon Hill</td>\n",
       "      <td>South Station</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77adadfb-4ac7-4cdf-aeab-6c4cfe8f7b26</td>\n",
       "      <td>8cf7e821-f0d3-49c6-8eba-e679c0ebcf6a</td>\n",
       "      <td>Taxi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>1.89</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1544695512211</td>\n",
       "      <td>Beacon Hill</td>\n",
       "      <td>North End</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>f2dfa974-f9d1-4e90-a0e6-77f7eea16956</td>\n",
       "      <td>8cf7e821-f0d3-49c6-8eba-e679c0ebcf6a</td>\n",
       "      <td>Taxi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>3.05</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1543812777435</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>North Station</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66e1e3af-6e64-4045-8739-d5f114b21f47</td>\n",
       "      <td>8cf7e821-f0d3-49c6-8eba-e679c0ebcf6a</td>\n",
       "      <td>Taxi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>773 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      distance cab_type     time_stamp    destination         source  price  \\\n",
       "18        1.11     Uber  1543673584211       West End      North End    NaN   \n",
       "31        2.48     Uber  1543794776318  South Station    Beacon Hill    NaN   \n",
       "40        2.94     Uber  1543523885298         Fenway  North Station    NaN   \n",
       "60        1.16     Uber  1544731816318       West End      North End    NaN   \n",
       "69        2.67     Uber  1543583283653    Beacon Hill      North End    NaN   \n",
       "...        ...      ...            ...            ...            ...    ...   \n",
       "9949      1.08     Uber  1543272429665      North End  North Station    NaN   \n",
       "9953      2.46     Uber  1545045010035    Beacon Hill         Fenway    NaN   \n",
       "9965      2.58     Uber  1544815809335    Beacon Hill  South Station    NaN   \n",
       "9985      1.89     Uber  1544695512211    Beacon Hill      North End    NaN   \n",
       "9994      3.05     Uber  1543812777435         Fenway  North Station    NaN   \n",
       "\n",
       "      surge_multiplier                                    id  \\\n",
       "18                 1.0  fa5fb705-03a0-4eb9-82d9-7fe80872f754   \n",
       "31                 1.0  eee70d94-6706-4b95-a8ce-0e34f0fa8f37   \n",
       "40                 1.0  7f47ff53-7cf2-4a6a-8049-83c90e042593   \n",
       "60                 1.0  43abdbe4-ab9e-4f39-afdc-31cfa375dc25   \n",
       "69                 1.0  80db1c49-9d51-4575-a4f4-1ec23b4d3e31   \n",
       "...                ...                                   ...   \n",
       "9949               1.0  74fffcba-da67-42d1-b585-13d546a125be   \n",
       "9953               1.0  18c2e91d-d594-4a22-9be7-0a5829efa4bf   \n",
       "9965               1.0  77adadfb-4ac7-4cdf-aeab-6c4cfe8f7b26   \n",
       "9985               1.0  f2dfa974-f9d1-4e90-a0e6-77f7eea16956   \n",
       "9994               1.0  66e1e3af-6e64-4045-8739-d5f114b21f47   \n",
       "\n",
       "                                product_id  name  \n",
       "18    8cf7e821-f0d3-49c6-8eba-e679c0ebcf6a  Taxi  \n",
       "31    8cf7e821-f0d3-49c6-8eba-e679c0ebcf6a  Taxi  \n",
       "40    8cf7e821-f0d3-49c6-8eba-e679c0ebcf6a  Taxi  \n",
       "60    8cf7e821-f0d3-49c6-8eba-e679c0ebcf6a  Taxi  \n",
       "69    8cf7e821-f0d3-49c6-8eba-e679c0ebcf6a  Taxi  \n",
       "...                                    ...   ...  \n",
       "9949  8cf7e821-f0d3-49c6-8eba-e679c0ebcf6a  Taxi  \n",
       "9953  8cf7e821-f0d3-49c6-8eba-e679c0ebcf6a  Taxi  \n",
       "9965  8cf7e821-f0d3-49c6-8eba-e679c0ebcf6a  Taxi  \n",
       "9985  8cf7e821-f0d3-49c6-8eba-e679c0ebcf6a  Taxi  \n",
       "9994  8cf7e821-f0d3-49c6-8eba-e679c0ebcf6a  Taxi  \n",
       "\n",
       "[773 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae340239-9767-43f7-92c3-b5ae53faef2e",
   "metadata": {},
   "source": [
    "Since we can't really see anything glaring from the null values, we can only conclude that the prices were never recorded. We will just drop those rows off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e33ab688-6d03-4ca8-a52f-ee9710ed62d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>cab_type</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>destination</th>\n",
       "      <th>source</th>\n",
       "      <th>price</th>\n",
       "      <th>surge_multiplier</th>\n",
       "      <th>id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.44</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1544952607890</td>\n",
       "      <td>North Station</td>\n",
       "      <td>Haymarket Square</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>424553bb-7174-41ea-aeb4-fe06d4f4b9d7</td>\n",
       "      <td>lyft_line</td>\n",
       "      <td>Shared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.44</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1543284023677</td>\n",
       "      <td>North Station</td>\n",
       "      <td>Haymarket Square</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4bd23055-6827-41c6-b23b-3c491f24e74d</td>\n",
       "      <td>lyft_premier</td>\n",
       "      <td>Lux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.44</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1543366822198</td>\n",
       "      <td>North Station</td>\n",
       "      <td>Haymarket Square</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>981a3613-77af-4620-a42a-0c0866077d1e</td>\n",
       "      <td>lyft</td>\n",
       "      <td>Lyft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.44</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1543553582749</td>\n",
       "      <td>North Station</td>\n",
       "      <td>Haymarket Square</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>c2d88af2-d278-4bfd-a8d0-29ca77cc5512</td>\n",
       "      <td>lyft_luxsuv</td>\n",
       "      <td>Lux Black XL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.44</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1543463360223</td>\n",
       "      <td>North Station</td>\n",
       "      <td>Haymarket Square</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>e0126e1f-8ca9-4f2e-82b3-50505a09db9a</td>\n",
       "      <td>lyft_plus</td>\n",
       "      <td>Lyft XL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>3.05</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1543504379037</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>North Station</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>934d2fbe-f978-4495-9786-da7b4dd21107</td>\n",
       "      <td>997acbb5-e102-41e1-b155-9df7de0a73f2</td>\n",
       "      <td>UberPool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3.05</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1543800477997</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>North Station</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>af8fd57c-fe7c-4584-bd1f-beef1a53ad42</td>\n",
       "      <td>6c84fd89-3f11-4782-9b50-97c468b19529</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>3.05</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1543407083241</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>North Station</td>\n",
       "      <td>19.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b3c5db97-554b-47bf-908b-3ac880e86103</td>\n",
       "      <td>6f72dfc5-27f1-42e8-84db-ccc7a75f6969</td>\n",
       "      <td>UberXL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>3.05</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1544896813623</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>North Station</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fcb35184-9047-43f7-8909-f62a7b17b6cf</td>\n",
       "      <td>6d318bcc-22a3-4af6-bddd-b409bfce1546</td>\n",
       "      <td>Black SUV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2.03</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1543812781166</td>\n",
       "      <td>Theatre District</td>\n",
       "      <td>Northeastern University</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7f0e8caf-e057-41eb-bdef-27eb14c88122</td>\n",
       "      <td>lyft_line</td>\n",
       "      <td>Shared</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9227 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      distance cab_type     time_stamp       destination  \\\n",
       "0         0.44     Lyft  1544952607890     North Station   \n",
       "1         0.44     Lyft  1543284023677     North Station   \n",
       "2         0.44     Lyft  1543366822198     North Station   \n",
       "3         0.44     Lyft  1543553582749     North Station   \n",
       "4         0.44     Lyft  1543463360223     North Station   \n",
       "...        ...      ...            ...               ...   \n",
       "9995      3.05     Uber  1543504379037            Fenway   \n",
       "9996      3.05     Uber  1543800477997            Fenway   \n",
       "9997      3.05     Uber  1543407083241            Fenway   \n",
       "9998      3.05     Uber  1544896813623            Fenway   \n",
       "9999      2.03     Lyft  1543812781166  Theatre District   \n",
       "\n",
       "                       source  price  surge_multiplier  \\\n",
       "0            Haymarket Square    5.0               1.0   \n",
       "1            Haymarket Square   11.0               1.0   \n",
       "2            Haymarket Square    7.0               1.0   \n",
       "3            Haymarket Square   26.0               1.0   \n",
       "4            Haymarket Square    9.0               1.0   \n",
       "...                       ...    ...               ...   \n",
       "9995            North Station   11.5               1.0   \n",
       "9996            North Station   26.0               1.0   \n",
       "9997            North Station   19.5               1.0   \n",
       "9998            North Station   36.5               1.0   \n",
       "9999  Northeastern University    7.0               1.0   \n",
       "\n",
       "                                        id  \\\n",
       "0     424553bb-7174-41ea-aeb4-fe06d4f4b9d7   \n",
       "1     4bd23055-6827-41c6-b23b-3c491f24e74d   \n",
       "2     981a3613-77af-4620-a42a-0c0866077d1e   \n",
       "3     c2d88af2-d278-4bfd-a8d0-29ca77cc5512   \n",
       "4     e0126e1f-8ca9-4f2e-82b3-50505a09db9a   \n",
       "...                                    ...   \n",
       "9995  934d2fbe-f978-4495-9786-da7b4dd21107   \n",
       "9996  af8fd57c-fe7c-4584-bd1f-beef1a53ad42   \n",
       "9997  b3c5db97-554b-47bf-908b-3ac880e86103   \n",
       "9998  fcb35184-9047-43f7-8909-f62a7b17b6cf   \n",
       "9999  7f0e8caf-e057-41eb-bdef-27eb14c88122   \n",
       "\n",
       "                                product_id          name  \n",
       "0                                lyft_line        Shared  \n",
       "1                             lyft_premier           Lux  \n",
       "2                                     lyft          Lyft  \n",
       "3                              lyft_luxsuv  Lux Black XL  \n",
       "4                                lyft_plus       Lyft XL  \n",
       "...                                    ...           ...  \n",
       "9995  997acbb5-e102-41e1-b155-9df7de0a73f2      UberPool  \n",
       "9996  6c84fd89-3f11-4782-9b50-97c468b19529         Black  \n",
       "9997  6f72dfc5-27f1-42e8-84db-ccc7a75f6969        UberXL  \n",
       "9998  6d318bcc-22a3-4af6-bddd-b409bfce1546     Black SUV  \n",
       "9999                             lyft_line        Shared  \n",
       "\n",
       "[9227 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df\n",
    " .dropna()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f8e562-ccaf-45c2-9728-28213af4ed16",
   "metadata": {},
   "source": [
    "### Feature engineering numerical columns\n",
    "\n",
    "Sometimes Timestamp columns tend to represent Unix time (the number of milliseconds since January 1st, 1970). Specific time data can be extracted from the timestamp column that may help predict cab fares, such as the month, hour of the day, whether it is rush hour, and so on.\n",
    "\n",
    "I will copy the last code and convert it into a function for the next stage of the feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0e5b22d-b9f2-42e5-a936-6f6d8e53eec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>cab_type</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>destination</th>\n",
       "      <th>source</th>\n",
       "      <th>price</th>\n",
       "      <th>surge_multiplier</th>\n",
       "      <th>id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3913</th>\n",
       "      <td>3.36</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1543317862189</td>\n",
       "      <td>Northeastern University</td>\n",
       "      <td>North Station</td>\n",
       "      <td>16.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1bbad703-ab15-4ed2-ad0d-3f3da5240b8c</td>\n",
       "      <td>lyft_plus</td>\n",
       "      <td>Lyft XL</td>\n",
       "      <td>1970-01-01 00:25:43.317862189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>3.08</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1543416685669</td>\n",
       "      <td>Northeastern University</td>\n",
       "      <td>West End</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b38b4ca5-317a-4b4a-b15f-bb78e01a3a28</td>\n",
       "      <td>9a0e7b09-b92b-4c41-9779-2ad22b4d779d</td>\n",
       "      <td>WAV</td>\n",
       "      <td>1970-01-01 00:25:43.416685669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9354</th>\n",
       "      <td>0.60</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1544893805700</td>\n",
       "      <td>South Station</td>\n",
       "      <td>Theatre District</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3099d03b-db48-4913-8871-948116a094d5</td>\n",
       "      <td>lyft_line</td>\n",
       "      <td>Shared</td>\n",
       "      <td>1970-01-01 00:25:44.893805700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3473</th>\n",
       "      <td>2.84</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1543425428309</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>West End</td>\n",
       "      <td>27.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2e76f105-448d-4f91-adac-8881902118c6</td>\n",
       "      <td>6d318bcc-22a3-4af6-bddd-b409bfce1546</td>\n",
       "      <td>Black SUV</td>\n",
       "      <td>1970-01-01 00:25:43.425428309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3722</th>\n",
       "      <td>2.73</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1543544581286</td>\n",
       "      <td>Back Bay</td>\n",
       "      <td>North End</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9ca032f4-6e37-4c22-9688-d0d9536e82fb</td>\n",
       "      <td>55c66225-fbe7-4fd5-9072-eab1ece5e23e</td>\n",
       "      <td>UberX</td>\n",
       "      <td>1970-01-01 00:25:43.544581286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      distance cab_type     time_stamp              destination  \\\n",
       "3913      3.36     Lyft  1543317862189  Northeastern University   \n",
       "1261      3.08     Uber  1543416685669  Northeastern University   \n",
       "9354      0.60     Lyft  1544893805700            South Station   \n",
       "3473      2.84     Uber  1543425428309                   Fenway   \n",
       "3722      2.73     Uber  1543544581286                 Back Bay   \n",
       "\n",
       "                source  price  surge_multiplier  \\\n",
       "3913     North Station   16.5               1.0   \n",
       "1261          West End   11.0               1.0   \n",
       "9354  Theatre District    3.0               1.0   \n",
       "3473          West End   27.5               1.0   \n",
       "3722         North End   15.0               1.0   \n",
       "\n",
       "                                        id  \\\n",
       "3913  1bbad703-ab15-4ed2-ad0d-3f3da5240b8c   \n",
       "1261  b38b4ca5-317a-4b4a-b15f-bb78e01a3a28   \n",
       "9354  3099d03b-db48-4913-8871-948116a094d5   \n",
       "3473  2e76f105-448d-4f91-adac-8881902118c6   \n",
       "3722  9ca032f4-6e37-4c22-9688-d0d9536e82fb   \n",
       "\n",
       "                                product_id       name  \\\n",
       "3913                             lyft_plus    Lyft XL   \n",
       "1261  9a0e7b09-b92b-4c41-9779-2ad22b4d779d        WAV   \n",
       "9354                             lyft_line     Shared   \n",
       "3473  6d318bcc-22a3-4af6-bddd-b409bfce1546  Black SUV   \n",
       "3722  55c66225-fbe7-4fd5-9072-eab1ece5e23e      UberX   \n",
       "\n",
       "                              date  \n",
       "3913 1970-01-01 00:25:43.317862189  \n",
       "1261 1970-01-01 00:25:43.416685669  \n",
       "9354 1970-01-01 00:25:44.893805700  \n",
       "3473 1970-01-01 00:25:43.425428309  \n",
       "3722 1970-01-01 00:25:43.544581286  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feat_eng(df):\n",
    "    return (df\n",
    "            .dropna()\n",
    "            .assign(date = pd.to_datetime(df['time_stamp']))\n",
    "           )\n",
    "\n",
    "df_cabs = feat_eng(df)\n",
    "df_cabs.sample(n=5, random_state=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9f97dc-2ff4-46e8-ae97-cf1617cfa225",
   "metadata": {},
   "source": [
    "The conversion is telling us that Uber and Lyft have existed and have collected data since the 1970's. There must be something wromg with our conversion. The extra decimal places are a clue that the conversion is incorrect.\n",
    "\n",
    "After trying several multipliers to make an appropriate conversion, it discovered that 10**6 gives the appropriate result. So we make the multiplication before the conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0247b235-3117-42b2-8861-58460ee6f64c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>cab_type</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>destination</th>\n",
       "      <th>source</th>\n",
       "      <th>price</th>\n",
       "      <th>surge_multiplier</th>\n",
       "      <th>id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3913</th>\n",
       "      <td>3.36</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1543317862189</td>\n",
       "      <td>Northeastern University</td>\n",
       "      <td>North Station</td>\n",
       "      <td>16.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1bbad703-ab15-4ed2-ad0d-3f3da5240b8c</td>\n",
       "      <td>lyft_plus</td>\n",
       "      <td>Lyft XL</td>\n",
       "      <td>2018-11-27 11:24:22.189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>3.08</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1543416685669</td>\n",
       "      <td>Northeastern University</td>\n",
       "      <td>West End</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b38b4ca5-317a-4b4a-b15f-bb78e01a3a28</td>\n",
       "      <td>9a0e7b09-b92b-4c41-9779-2ad22b4d779d</td>\n",
       "      <td>WAV</td>\n",
       "      <td>2018-11-28 14:51:25.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9354</th>\n",
       "      <td>0.60</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1544893805700</td>\n",
       "      <td>South Station</td>\n",
       "      <td>Theatre District</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3099d03b-db48-4913-8871-948116a094d5</td>\n",
       "      <td>lyft_line</td>\n",
       "      <td>Shared</td>\n",
       "      <td>2018-12-15 17:10:05.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3473</th>\n",
       "      <td>2.84</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1543425428309</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>West End</td>\n",
       "      <td>27.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2e76f105-448d-4f91-adac-8881902118c6</td>\n",
       "      <td>6d318bcc-22a3-4af6-bddd-b409bfce1546</td>\n",
       "      <td>Black SUV</td>\n",
       "      <td>2018-11-28 17:17:08.309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3722</th>\n",
       "      <td>2.73</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1543544581286</td>\n",
       "      <td>Back Bay</td>\n",
       "      <td>North End</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9ca032f4-6e37-4c22-9688-d0d9536e82fb</td>\n",
       "      <td>55c66225-fbe7-4fd5-9072-eab1ece5e23e</td>\n",
       "      <td>UberX</td>\n",
       "      <td>2018-11-30 02:23:01.286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      distance cab_type     time_stamp              destination  \\\n",
       "3913      3.36     Lyft  1543317862189  Northeastern University   \n",
       "1261      3.08     Uber  1543416685669  Northeastern University   \n",
       "9354      0.60     Lyft  1544893805700            South Station   \n",
       "3473      2.84     Uber  1543425428309                   Fenway   \n",
       "3722      2.73     Uber  1543544581286                 Back Bay   \n",
       "\n",
       "                source  price  surge_multiplier  \\\n",
       "3913     North Station   16.5               1.0   \n",
       "1261          West End   11.0               1.0   \n",
       "9354  Theatre District    3.0               1.0   \n",
       "3473          West End   27.5               1.0   \n",
       "3722         North End   15.0               1.0   \n",
       "\n",
       "                                        id  \\\n",
       "3913  1bbad703-ab15-4ed2-ad0d-3f3da5240b8c   \n",
       "1261  b38b4ca5-317a-4b4a-b15f-bb78e01a3a28   \n",
       "9354  3099d03b-db48-4913-8871-948116a094d5   \n",
       "3473  2e76f105-448d-4f91-adac-8881902118c6   \n",
       "3722  9ca032f4-6e37-4c22-9688-d0d9536e82fb   \n",
       "\n",
       "                                product_id       name                    date  \n",
       "3913                             lyft_plus    Lyft XL 2018-11-27 11:24:22.189  \n",
       "1261  9a0e7b09-b92b-4c41-9779-2ad22b4d779d        WAV 2018-11-28 14:51:25.669  \n",
       "9354                             lyft_line     Shared 2018-12-15 17:10:05.700  \n",
       "3473  6d318bcc-22a3-4af6-bddd-b409bfce1546  Black SUV 2018-11-28 17:17:08.309  \n",
       "3722  55c66225-fbe7-4fd5-9072-eab1ece5e23e      UberX 2018-11-30 02:23:01.286  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feat_eng(df):\n",
    "    return (df\n",
    "            .dropna()\n",
    "            .assign(date = pd.to_datetime(df['time_stamp']*(10**6)))\n",
    "           )\n",
    "\n",
    "df_cabs = feat_eng(df)\n",
    "df_cabs.sample(n=5, random_state=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c8855d-5e54-435d-a67d-339378b798bd",
   "metadata": {},
   "source": [
    "With a datetime column, you can extract new columns, such as `month`, `hour`, and `day of week`, after importing `datetime`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f197d2b9-d57f-462d-a2c5-2aea8167ca36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>cab_type</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>destination</th>\n",
       "      <th>source</th>\n",
       "      <th>price</th>\n",
       "      <th>surge_multiplier</th>\n",
       "      <th>id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3913</th>\n",
       "      <td>3.36</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1543317862189</td>\n",
       "      <td>Northeastern University</td>\n",
       "      <td>North Station</td>\n",
       "      <td>16.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1bbad703-ab15-4ed2-ad0d-3f3da5240b8c</td>\n",
       "      <td>lyft_plus</td>\n",
       "      <td>Lyft XL</td>\n",
       "      <td>2018-11-27 11:24:22.189</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>3.08</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1543416685669</td>\n",
       "      <td>Northeastern University</td>\n",
       "      <td>West End</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b38b4ca5-317a-4b4a-b15f-bb78e01a3a28</td>\n",
       "      <td>9a0e7b09-b92b-4c41-9779-2ad22b4d779d</td>\n",
       "      <td>WAV</td>\n",
       "      <td>2018-11-28 14:51:25.669</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9354</th>\n",
       "      <td>0.60</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1544893805700</td>\n",
       "      <td>South Station</td>\n",
       "      <td>Theatre District</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3099d03b-db48-4913-8871-948116a094d5</td>\n",
       "      <td>lyft_line</td>\n",
       "      <td>Shared</td>\n",
       "      <td>2018-12-15 17:10:05.700</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3473</th>\n",
       "      <td>2.84</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1543425428309</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>West End</td>\n",
       "      <td>27.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2e76f105-448d-4f91-adac-8881902118c6</td>\n",
       "      <td>6d318bcc-22a3-4af6-bddd-b409bfce1546</td>\n",
       "      <td>Black SUV</td>\n",
       "      <td>2018-11-28 17:17:08.309</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3722</th>\n",
       "      <td>2.73</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1543544581286</td>\n",
       "      <td>Back Bay</td>\n",
       "      <td>North End</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9ca032f4-6e37-4c22-9688-d0d9536e82fb</td>\n",
       "      <td>55c66225-fbe7-4fd5-9072-eab1ece5e23e</td>\n",
       "      <td>UberX</td>\n",
       "      <td>2018-11-30 02:23:01.286</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      distance cab_type     time_stamp              destination  \\\n",
       "3913      3.36     Lyft  1543317862189  Northeastern University   \n",
       "1261      3.08     Uber  1543416685669  Northeastern University   \n",
       "9354      0.60     Lyft  1544893805700            South Station   \n",
       "3473      2.84     Uber  1543425428309                   Fenway   \n",
       "3722      2.73     Uber  1543544581286                 Back Bay   \n",
       "\n",
       "                source  price  surge_multiplier  \\\n",
       "3913     North Station   16.5               1.0   \n",
       "1261          West End   11.0               1.0   \n",
       "9354  Theatre District    3.0               1.0   \n",
       "3473          West End   27.5               1.0   \n",
       "3722         North End   15.0               1.0   \n",
       "\n",
       "                                        id  \\\n",
       "3913  1bbad703-ab15-4ed2-ad0d-3f3da5240b8c   \n",
       "1261  b38b4ca5-317a-4b4a-b15f-bb78e01a3a28   \n",
       "9354  3099d03b-db48-4913-8871-948116a094d5   \n",
       "3473  2e76f105-448d-4f91-adac-8881902118c6   \n",
       "3722  9ca032f4-6e37-4c22-9688-d0d9536e82fb   \n",
       "\n",
       "                                product_id       name                    date  \\\n",
       "3913                             lyft_plus    Lyft XL 2018-11-27 11:24:22.189   \n",
       "1261  9a0e7b09-b92b-4c41-9779-2ad22b4d779d        WAV 2018-11-28 14:51:25.669   \n",
       "9354                             lyft_line     Shared 2018-12-15 17:10:05.700   \n",
       "3473  6d318bcc-22a3-4af6-bddd-b409bfce1546  Black SUV 2018-11-28 17:17:08.309   \n",
       "3722  55c66225-fbe7-4fd5-9072-eab1ece5e23e      UberX 2018-11-30 02:23:01.286   \n",
       "\n",
       "      month  hour  dayofweek  \n",
       "3913     11    11          1  \n",
       "1261     11    14          2  \n",
       "9354     12    17          5  \n",
       "3473     11    17          2  \n",
       "3722     11     2          4  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feat_eng(df):\n",
    "    return (df\n",
    "            .dropna()\n",
    "            .assign(date = pd.to_datetime(df['time_stamp']*(10**6)),\n",
    "                   month = lambda x: x['date'].dt.month,\n",
    "                    hour = lambda x: x['date'].dt.hour,\n",
    "                    dayofweek = lambda x: x['date'].dt.dayofweek)\n",
    "           )\n",
    "\n",
    "df_cabs = feat_eng(df)\n",
    "df_cabs.sample(n=5, random_state=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783369b4-3716-4a61-8e56-f1b024fd5e77",
   "metadata": {},
   "source": [
    "Next we determine whether a day of the week is a weekend by checking whether the column `dayofweek` is equivalent to 5 or 6, which represent Saturday or Sunday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd5df04b-9eb1-474b-b671-9a5e26da284d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>cab_type</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>destination</th>\n",
       "      <th>source</th>\n",
       "      <th>price</th>\n",
       "      <th>surge_multiplier</th>\n",
       "      <th>id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3913</th>\n",
       "      <td>3.36</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1543317862189</td>\n",
       "      <td>Northeastern University</td>\n",
       "      <td>North Station</td>\n",
       "      <td>16.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1bbad703-ab15-4ed2-ad0d-3f3da5240b8c</td>\n",
       "      <td>lyft_plus</td>\n",
       "      <td>Lyft XL</td>\n",
       "      <td>2018-11-27 11:24:22.189</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>3.08</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1543416685669</td>\n",
       "      <td>Northeastern University</td>\n",
       "      <td>West End</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b38b4ca5-317a-4b4a-b15f-bb78e01a3a28</td>\n",
       "      <td>9a0e7b09-b92b-4c41-9779-2ad22b4d779d</td>\n",
       "      <td>WAV</td>\n",
       "      <td>2018-11-28 14:51:25.669</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9354</th>\n",
       "      <td>0.60</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1544893805700</td>\n",
       "      <td>South Station</td>\n",
       "      <td>Theatre District</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3099d03b-db48-4913-8871-948116a094d5</td>\n",
       "      <td>lyft_line</td>\n",
       "      <td>Shared</td>\n",
       "      <td>2018-12-15 17:10:05.700</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3473</th>\n",
       "      <td>2.84</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1543425428309</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>West End</td>\n",
       "      <td>27.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2e76f105-448d-4f91-adac-8881902118c6</td>\n",
       "      <td>6d318bcc-22a3-4af6-bddd-b409bfce1546</td>\n",
       "      <td>Black SUV</td>\n",
       "      <td>2018-11-28 17:17:08.309</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3722</th>\n",
       "      <td>2.73</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1543544581286</td>\n",
       "      <td>Back Bay</td>\n",
       "      <td>North End</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9ca032f4-6e37-4c22-9688-d0d9536e82fb</td>\n",
       "      <td>55c66225-fbe7-4fd5-9072-eab1ece5e23e</td>\n",
       "      <td>UberX</td>\n",
       "      <td>2018-11-30 02:23:01.286</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      distance cab_type     time_stamp              destination  \\\n",
       "3913      3.36     Lyft  1543317862189  Northeastern University   \n",
       "1261      3.08     Uber  1543416685669  Northeastern University   \n",
       "9354      0.60     Lyft  1544893805700            South Station   \n",
       "3473      2.84     Uber  1543425428309                   Fenway   \n",
       "3722      2.73     Uber  1543544581286                 Back Bay   \n",
       "\n",
       "                source  price  surge_multiplier  \\\n",
       "3913     North Station   16.5               1.0   \n",
       "1261          West End   11.0               1.0   \n",
       "9354  Theatre District    3.0               1.0   \n",
       "3473          West End   27.5               1.0   \n",
       "3722         North End   15.0               1.0   \n",
       "\n",
       "                                        id  \\\n",
       "3913  1bbad703-ab15-4ed2-ad0d-3f3da5240b8c   \n",
       "1261  b38b4ca5-317a-4b4a-b15f-bb78e01a3a28   \n",
       "9354  3099d03b-db48-4913-8871-948116a094d5   \n",
       "3473  2e76f105-448d-4f91-adac-8881902118c6   \n",
       "3722  9ca032f4-6e37-4c22-9688-d0d9536e82fb   \n",
       "\n",
       "                                product_id       name                    date  \\\n",
       "3913                             lyft_plus    Lyft XL 2018-11-27 11:24:22.189   \n",
       "1261  9a0e7b09-b92b-4c41-9779-2ad22b4d779d        WAV 2018-11-28 14:51:25.669   \n",
       "9354                             lyft_line     Shared 2018-12-15 17:10:05.700   \n",
       "3473  6d318bcc-22a3-4af6-bddd-b409bfce1546  Black SUV 2018-11-28 17:17:08.309   \n",
       "3722  55c66225-fbe7-4fd5-9072-eab1ece5e23e      UberX 2018-11-30 02:23:01.286   \n",
       "\n",
       "      month  hour  dayofweek  weekend  \n",
       "3913     11    11          1        0  \n",
       "1261     11    14          2        0  \n",
       "9354     12    17          5        1  \n",
       "3473     11    17          2        0  \n",
       "3722     11     2          4        0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feat_eng(df):\n",
    "    return (df\n",
    "            .dropna()\n",
    "            .assign(date = pd.to_datetime(df['time_stamp']*(10**6)),\n",
    "                    month = lambda x: x['date'].dt.month,\n",
    "                    hour = lambda x: x['date'].dt.hour,\n",
    "                    dayofweek = lambda x: x['date'].dt.dayofweek,\n",
    "                    weekend = lambda x: np.where((x['dayofweek'] == 5) | (x['dayofweek'] == 6), 1, 0)\n",
    "                   )\n",
    "           )\n",
    "\n",
    "df_cabs = feat_eng(df)\n",
    "df_cabs.sample(n=5, random_state=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64b56d1-34b1-4e3e-85f9-940161cce154",
   "metadata": {},
   "source": [
    "Using NumPy for vectorization is a great idea, especially for large datasets, as it often provides performance enhancements over pure pandas operations. This approach should be faster than applying a function to each row, as `np.where` operates on the entire array at once.\n",
    "\n",
    "- `np.where` is a vectorized conditional function from NumPy. It works like an efficient, element-wise version of an if-else statement.\n",
    "- `(df['dayofweek'] == 5) | (df['dayofweek'] == 6)` creates a boolean condition where `True` is assigned for weekend days (assuming 5 and 6 represent Saturday and Sunday, respectively).\n",
    "- The first argument after the condition in `np.where` is the value to assign when the condition is `True` (in this case, `1`), and the second argument is the value for `False` (`0`).\n",
    "\n",
    "The same strategy can be implemented to create a `rush_hour` column by seeing whether the hour is between 6â€“10 AM (hours 6â€“10) and 3â€“7 PM (hours 15â€“19) and not the weekend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c234cff-51d1-4143-8f3b-cf370d7e2a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>cab_type</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>destination</th>\n",
       "      <th>source</th>\n",
       "      <th>price</th>\n",
       "      <th>surge_multiplier</th>\n",
       "      <th>id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>weekend</th>\n",
       "      <th>rush_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3913</th>\n",
       "      <td>3.36</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1543317862189</td>\n",
       "      <td>Northeastern University</td>\n",
       "      <td>North Station</td>\n",
       "      <td>16.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1bbad703-ab15-4ed2-ad0d-3f3da5240b8c</td>\n",
       "      <td>lyft_plus</td>\n",
       "      <td>Lyft XL</td>\n",
       "      <td>2018-11-27 11:24:22.189</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>3.08</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1543416685669</td>\n",
       "      <td>Northeastern University</td>\n",
       "      <td>West End</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b38b4ca5-317a-4b4a-b15f-bb78e01a3a28</td>\n",
       "      <td>9a0e7b09-b92b-4c41-9779-2ad22b4d779d</td>\n",
       "      <td>WAV</td>\n",
       "      <td>2018-11-28 14:51:25.669</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9354</th>\n",
       "      <td>0.60</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1544893805700</td>\n",
       "      <td>South Station</td>\n",
       "      <td>Theatre District</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3099d03b-db48-4913-8871-948116a094d5</td>\n",
       "      <td>lyft_line</td>\n",
       "      <td>Shared</td>\n",
       "      <td>2018-12-15 17:10:05.700</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3473</th>\n",
       "      <td>2.84</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1543425428309</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>West End</td>\n",
       "      <td>27.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2e76f105-448d-4f91-adac-8881902118c6</td>\n",
       "      <td>6d318bcc-22a3-4af6-bddd-b409bfce1546</td>\n",
       "      <td>Black SUV</td>\n",
       "      <td>2018-11-28 17:17:08.309</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3722</th>\n",
       "      <td>2.73</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1543544581286</td>\n",
       "      <td>Back Bay</td>\n",
       "      <td>North End</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9ca032f4-6e37-4c22-9688-d0d9536e82fb</td>\n",
       "      <td>55c66225-fbe7-4fd5-9072-eab1ece5e23e</td>\n",
       "      <td>UberX</td>\n",
       "      <td>2018-11-30 02:23:01.286</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      distance cab_type     time_stamp              destination  \\\n",
       "3913      3.36     Lyft  1543317862189  Northeastern University   \n",
       "1261      3.08     Uber  1543416685669  Northeastern University   \n",
       "9354      0.60     Lyft  1544893805700            South Station   \n",
       "3473      2.84     Uber  1543425428309                   Fenway   \n",
       "3722      2.73     Uber  1543544581286                 Back Bay   \n",
       "\n",
       "                source  price  surge_multiplier  \\\n",
       "3913     North Station   16.5               1.0   \n",
       "1261          West End   11.0               1.0   \n",
       "9354  Theatre District    3.0               1.0   \n",
       "3473          West End   27.5               1.0   \n",
       "3722         North End   15.0               1.0   \n",
       "\n",
       "                                        id  \\\n",
       "3913  1bbad703-ab15-4ed2-ad0d-3f3da5240b8c   \n",
       "1261  b38b4ca5-317a-4b4a-b15f-bb78e01a3a28   \n",
       "9354  3099d03b-db48-4913-8871-948116a094d5   \n",
       "3473  2e76f105-448d-4f91-adac-8881902118c6   \n",
       "3722  9ca032f4-6e37-4c22-9688-d0d9536e82fb   \n",
       "\n",
       "                                product_id       name                    date  \\\n",
       "3913                             lyft_plus    Lyft XL 2018-11-27 11:24:22.189   \n",
       "1261  9a0e7b09-b92b-4c41-9779-2ad22b4d779d        WAV 2018-11-28 14:51:25.669   \n",
       "9354                             lyft_line     Shared 2018-12-15 17:10:05.700   \n",
       "3473  6d318bcc-22a3-4af6-bddd-b409bfce1546  Black SUV 2018-11-28 17:17:08.309   \n",
       "3722  55c66225-fbe7-4fd5-9072-eab1ece5e23e      UberX 2018-11-30 02:23:01.286   \n",
       "\n",
       "      month  hour  dayofweek  weekend  rush_hour  \n",
       "3913     11    11          1        0          0  \n",
       "1261     11    14          2        0          0  \n",
       "9354     12    17          5        1          0  \n",
       "3473     11    17          2        0          1  \n",
       "3722     11     2          4        0          0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feat_eng(df):\n",
    "    # Define rush hour conditions\n",
    "    rush_hours = [6, 7, 8, 9, 15, 16, 17, 18]\n",
    "    \n",
    "    return (df\n",
    "            .dropna()\n",
    "            .assign(date = pd.to_datetime(df['time_stamp']*(10**6)),\n",
    "                    month = lambda x: x['date'].dt.month,\n",
    "                    hour = lambda x: x['date'].dt.hour,\n",
    "                    dayofweek = lambda x: x['date'].dt.dayofweek,\n",
    "                    weekend = lambda x: np.where((x['dayofweek'] == 5) | (x['dayofweek'] == 6), 1, 0),\n",
    "                    rush_hour = lambda x: np.where((np.isin(x['hour'], \n",
    "                                                            rush_hours) & (x['weekend'] == 0)), 1, 0)\n",
    "                   )\n",
    "           )\n",
    "\n",
    "df_cabs = feat_eng(df)\n",
    "df_cabs.sample(n=5, random_state=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f50523b-e6e9-48d6-8503-1fde13c5a8db",
   "metadata": {},
   "source": [
    "In this code:\n",
    "\n",
    "- `np.isin(df['hour'], rush_hours)` checks if each element in `df['hour']` is in the list of rush hour times.\n",
    "- `& (df['weekend'] == 0)` further filters the condition to non-weekend days.\n",
    "- Finally, `np.where` is used to assign `1` where the condition is met, and `0` otherwise.\n",
    "\n",
    "### Feature engineering categorical columns\n",
    "\n",
    "Feature engineering often involves converting categorical data into numerical forms for machine learning models. Here's a concise overview of the process and alternatives:\n",
    "\n",
    "1. **Standard Methods**: \n",
    "   - **`pd.get_dummies`**: This pandas function is commonly used to convert categorical columns into a series of binary (0s and 1s) columns, indicating the presence or absence of each category.\n",
    "   - **`OneHotEncoder` from Scikit-learn**: Similar to `pd.get_dummies`, but it creates sparse matrices which are memory-efficient, especially useful for large datasets with many categories. It's a preferred option in scenarios like XGBoost model deployment, as discussed in Chapter 10 of your referenced material.\n",
    "\n",
    "2. **Alternatives to Binary Encoding**: \n",
    "   - While binary encoding (0s and 1s) is standard, other methods might yield better results in certain cases.\n",
    "   - **Frequency Encoding**: This method involves converting categories into their frequencies within the column. Here, each category is represented by its percentage occurrence in the column. It provides a different numerical representation that might be more informative, especially in datasets where the frequency of categories is important.\n",
    "\n",
    "In summary, while `pd.get_dummies` and `OneHotEncoder` are common techniques for handling categorical data, exploring alternative methods like frequency encoding can be beneficial, particularly when the relative frequency of categories carries significant information for the model.\n",
    "\n",
    "### Engineering frequency columns\n",
    "\n",
    "To engineer a categorical column, such as `cab_type`, we will first view the number of values for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b48734e-f67f-4ddf-a03f-991d67ebba4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cab_type\n",
       "Uber    4654\n",
       "Lyft    4573\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cabs['cab_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1904f831-85b2-46a1-8260-03cfc87364c9",
   "metadata": {},
   "source": [
    "We next use `groupby` to place the `counts` in a new column. We will do that inside the function we have been building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a460470c-b4df-4697-999f-3a4cbc4fe9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>cab_type</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>destination</th>\n",
       "      <th>source</th>\n",
       "      <th>price</th>\n",
       "      <th>surge_multiplier</th>\n",
       "      <th>id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>weekend</th>\n",
       "      <th>rush_hour</th>\n",
       "      <th>cab_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>3.05</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1543504379037</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>North Station</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>934d2fbe-f978-4495-9786-da7b4dd21107</td>\n",
       "      <td>997acbb5-e102-41e1-b155-9df7de0a73f2</td>\n",
       "      <td>UberPool</td>\n",
       "      <td>2018-11-29 15:12:59.037</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.504389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3.05</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1543800477997</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>North Station</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>af8fd57c-fe7c-4584-bd1f-beef1a53ad42</td>\n",
       "      <td>6c84fd89-3f11-4782-9b50-97c468b19529</td>\n",
       "      <td>Black</td>\n",
       "      <td>2018-12-03 01:27:57.997</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.504389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>3.05</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1543407083241</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>North Station</td>\n",
       "      <td>19.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b3c5db97-554b-47bf-908b-3ac880e86103</td>\n",
       "      <td>6f72dfc5-27f1-42e8-84db-ccc7a75f6969</td>\n",
       "      <td>UberXL</td>\n",
       "      <td>2018-11-28 12:11:23.241</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.504389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>3.05</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1544896813623</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>North Station</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fcb35184-9047-43f7-8909-f62a7b17b6cf</td>\n",
       "      <td>6d318bcc-22a3-4af6-bddd-b409bfce1546</td>\n",
       "      <td>Black SUV</td>\n",
       "      <td>2018-12-15 18:00:13.623</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.504389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2.03</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1543812781166</td>\n",
       "      <td>Theatre District</td>\n",
       "      <td>Northeastern University</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7f0e8caf-e057-41eb-bdef-27eb14c88122</td>\n",
       "      <td>lyft_line</td>\n",
       "      <td>Shared</td>\n",
       "      <td>2018-12-03 04:53:01.166</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.495611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      distance cab_type     time_stamp       destination  \\\n",
       "9995      3.05     Uber  1543504379037            Fenway   \n",
       "9996      3.05     Uber  1543800477997            Fenway   \n",
       "9997      3.05     Uber  1543407083241            Fenway   \n",
       "9998      3.05     Uber  1544896813623            Fenway   \n",
       "9999      2.03     Lyft  1543812781166  Theatre District   \n",
       "\n",
       "                       source  price  surge_multiplier  \\\n",
       "9995            North Station   11.5               1.0   \n",
       "9996            North Station   26.0               1.0   \n",
       "9997            North Station   19.5               1.0   \n",
       "9998            North Station   36.5               1.0   \n",
       "9999  Northeastern University    7.0               1.0   \n",
       "\n",
       "                                        id  \\\n",
       "9995  934d2fbe-f978-4495-9786-da7b4dd21107   \n",
       "9996  af8fd57c-fe7c-4584-bd1f-beef1a53ad42   \n",
       "9997  b3c5db97-554b-47bf-908b-3ac880e86103   \n",
       "9998  fcb35184-9047-43f7-8909-f62a7b17b6cf   \n",
       "9999  7f0e8caf-e057-41eb-bdef-27eb14c88122   \n",
       "\n",
       "                                product_id       name                    date  \\\n",
       "9995  997acbb5-e102-41e1-b155-9df7de0a73f2   UberPool 2018-11-29 15:12:59.037   \n",
       "9996  6c84fd89-3f11-4782-9b50-97c468b19529      Black 2018-12-03 01:27:57.997   \n",
       "9997  6f72dfc5-27f1-42e8-84db-ccc7a75f6969     UberXL 2018-11-28 12:11:23.241   \n",
       "9998  6d318bcc-22a3-4af6-bddd-b409bfce1546  Black SUV 2018-12-15 18:00:13.623   \n",
       "9999                             lyft_line     Shared 2018-12-03 04:53:01.166   \n",
       "\n",
       "      month  hour  dayofweek  weekend  rush_hour  cab_freq  \n",
       "9995     11    15          3        0          1  0.504389  \n",
       "9996     12     1          0        0          0  0.504389  \n",
       "9997     11    12          2        0          0  0.504389  \n",
       "9998     12    18          5        1          0  0.504389  \n",
       "9999     12     4          0        0          0  0.495611  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feat_eng(df):\n",
    "    # Define rush hour conditions\n",
    "    rush_hours = [6, 7, 8, 9, 15, 16, 17, 18]\n",
    "    \n",
    "    return (df\n",
    "            .dropna()\n",
    "            .assign(date = pd.to_datetime(df['time_stamp']*(10**6)),\n",
    "                    month = lambda x: x['date'].dt.month,\n",
    "                    hour = lambda x: x['date'].dt.hour,\n",
    "                    dayofweek = lambda x: x['date'].dt.dayofweek,\n",
    "                    weekend = lambda x: np.where((x['dayofweek'] == 5) | (x['dayofweek'] == 6), 1, 0),\n",
    "                    rush_hour = lambda x: np.where((np.isin(x['hour'], \n",
    "                                                            rush_hours) & (x['weekend'] == 0)), 1, 0),\n",
    "                    cab_freq = lambda x: x.groupby('cab_type')['cab_type'].transform('count')/len(x)\n",
    "                   )\n",
    "           )\n",
    "\n",
    "df_cabs = feat_eng(df)\n",
    "df_cabs.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb59f25-bcb1-455e-b51a-3ecb0c416eb7",
   "metadata": {},
   "source": [
    "Let's break down the code `df_cabs.groupby('cab_type')['cab_type'].transform('count') / len(df_cabs)`:\n",
    "\n",
    "1. **Grouping by 'cab_type'**:\n",
    "   - `df_cabs.groupby('cab_type')`: This part of the code groups the DataFrame `df_cabs` by the values in the 'cab_type' column. It essentially organizes the data such that rows with the same 'cab_type' value are grouped together.\n",
    "\n",
    "2. **Selecting the 'cab_type' Column**:\n",
    "   - `['cab_type']`: After grouping, this code selects the 'cab_type' column within each group. It's a bit redundant in this case since we're grouping by 'cab_type' and then selecting the same column, but it's necessary for the next step.\n",
    "\n",
    "3. **Applying the Transform Function**:\n",
    "   - `.transform('count')`: The `transform` function is applied to the 'cab_type' column of each group. The argument `'count'` tells transform to count the number of occurrences of each unique 'cab_type' value in the DataFrame. Unlike aggregation functions like `groupby().count()`, which reduce the data to the number of unique groups, `transform` maintains the original DataFrame's shape. It will replicate the count for each occurrence of 'cab_type'.\n",
    "\n",
    "4. **Dividing by the Length of the DataFrame**:\n",
    "   - `/ len(df_cabs)`: The total count for each 'cab_type' group obtained from `transform('count')` is then divided by the total number of rows in `df_cabs` (given by `len(df_cabs)`). This step converts the counts into frequencies, representing the proportion of each 'cab_type' category within the entire DataFrame.\n",
    "\n",
    "In summary, this line of code calculates the frequency (as a proportion of the total number of rows) of each unique value in the 'cab_type' column. The result is a Series where each value corresponds to the frequency of the 'cab_type' for that row. This technique is often used in feature engineering to replace categorical variables with a numeric representation that reflects the prevalence of each category within the dataset.\n",
    "\n",
    "### Mean Encoding in Feature Engineering\r\n",
    "In the domain of machine learning, particularly in Kaggle competitions, **Mean Encoding** has emerged as a noteworthy technique. While it's not necessarily superior to one-hot encoding in every scenario, its effectiveness in certain competitions makes it a valuable method to consider.\n",
    "\n",
    "\r\n",
    "**Mean Encoding**, also known as **Target Encoding**, is a technique in machine learning where categorical variables are replaced with the mean of the target variable. For example, if you have a categorical feature 'color' with the value 'orange', and this color corresponds to seven instances of the target variable being 1 and three instances of it being 0, the mean encoding for 'orange' would be 0.7 (calculated as 7/10).\r\n",
    "\r\n",
    "#### Key Points:\r\n",
    "\r\n",
    "- **Purpose**: It transforms categorical columns into numerical values based on the mean of the target variable, providing a potentially more meaningful representation of the category in relation to the target.\r\n",
    "\r\n",
    "- **Data Leakage Concerns**: One major issue with mean encoding is the risk of data leakage. Data leakage happens when information from the target variable influences the predictor variables, leading to overly optimistic performance estimates. This can occur if the mean encoding uses the target data in a way that is not representative of how the model will encounter data in the real world.\r\n",
    "\r\n",
    "- **Regularization**: To mitigate data leakage and overfitting, regularization techniques are employed. Regularization adjusts the encoding to be more conservative, thereby reducing the model's complexity and its tendency to overfit on the training data.\r\n",
    "\r\n",
    "- **Applicability**: Mean encoding is particularly effective for large datasets with a deep distribution of categorical values. It's most beneficial when the distribution of mean values in the training data is similar to that in the new, incoming data.\r\n",
    "\r\n",
    "- **Scikit-learn's `TargetEncoder`**: To facilitate mean encoding while addressing data leakage and overfitting, scikit-learn offers the `TargetEncoder`. This tool automatically applies mean encoding with built-in options for r\n",
    "\n",
    "- **Comparative Analysis**: Mean encoding isn't presented as a blanket replacement for one-hot encoding. Instead, it's an alternative that has shown promise in specific contexts, particularly in Kaggle competitions.\n",
    "\n",
    "- **Practical Application**: The value of mean encoding lies in its potential to improve model performance in certain datasets. By replacing categorical values with the mean of the target variable, it offers a different perspective on the data, which can sometimes lead to better predictive accuracy.\n",
    "\n",
    "-  **Resource for In-Depth Understanding**: For a detailed exploration of mean encoding, a comprehensive study is available on Kaggle, titled \"Mean Likelihood Encodings: A Comprehensive Study\" (available [here](https://www.kaggle.com/vprokopev/mean-likelihood-encodings-a-comprehensive-study)). This resource provides extensive insights into the technique.egularization.\r\n",
    "\r\n",
    "#### Example:\r\n",
    "Suppose a dataset for predicting house prices includes a categorical feature 'Neighborhood'. If houses in 'Neighborhood A' typically sell for higher prices than those in 'Neighborhood B', mean encoding will assign a higher numerical value to 'Neighborhood A' based on the average sale price (target variable) associated with it.\r\n",
    "\r\n",
    "#### Conclusion:\r\n",
    "Mean encoding is a powerful feature engineering technique tested in competitions like Kaggle. It converts categorical data into a numerical format that reflects the mean of the target variable, offering a nuanced representation of categories in relation to the target. However, its implementation must be handled carefully to avoid data leakage and overfitting, with regularization playing a crucial role in ensuring model robustness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2069f45a-9c30-4d36-b10c-488fe17e9e72",
   "metadata": {},
   "source": [
    "We continue to build our `feat_eng` function with the following steps.\n",
    "```python\n",
    "encoder = TargetEncoder()\n",
    "```\n",
    "After initializing encoder as above, we will next create a new column to apply the mean encoding using the `fit_transform` method on the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4881565-de09-4d04-8e03-4e27b78a4a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>cab_type</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>destination</th>\n",
       "      <th>source</th>\n",
       "      <th>price</th>\n",
       "      <th>surge_multiplier</th>\n",
       "      <th>id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>weekend</th>\n",
       "      <th>rush_hour</th>\n",
       "      <th>cab_freq</th>\n",
       "      <th>cab_type_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>3.05</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1543504379037</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>North Station</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>934d2fbe-f978-4495-9786-da7b4dd21107</td>\n",
       "      <td>997acbb5-e102-41e1-b155-9df7de0a73f2</td>\n",
       "      <td>UberPool</td>\n",
       "      <td>2018-11-29 15:12:59.037</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.504389</td>\n",
       "      <td>15.743446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3.05</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1543800477997</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>North Station</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>af8fd57c-fe7c-4584-bd1f-beef1a53ad42</td>\n",
       "      <td>6c84fd89-3f11-4782-9b50-97c468b19529</td>\n",
       "      <td>Black</td>\n",
       "      <td>2018-12-03 01:27:57.997</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.504389</td>\n",
       "      <td>15.743446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>3.05</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1543407083241</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>North Station</td>\n",
       "      <td>19.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b3c5db97-554b-47bf-908b-3ac880e86103</td>\n",
       "      <td>6f72dfc5-27f1-42e8-84db-ccc7a75f6969</td>\n",
       "      <td>UberXL</td>\n",
       "      <td>2018-11-28 12:11:23.241</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.504389</td>\n",
       "      <td>15.743446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>3.05</td>\n",
       "      <td>Uber</td>\n",
       "      <td>1544896813623</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>North Station</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fcb35184-9047-43f7-8909-f62a7b17b6cf</td>\n",
       "      <td>6d318bcc-22a3-4af6-bddd-b409bfce1546</td>\n",
       "      <td>Black SUV</td>\n",
       "      <td>2018-12-15 18:00:13.623</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.504389</td>\n",
       "      <td>15.743446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2.03</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1543812781166</td>\n",
       "      <td>Theatre District</td>\n",
       "      <td>Northeastern University</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7f0e8caf-e057-41eb-bdef-27eb14c88122</td>\n",
       "      <td>lyft_line</td>\n",
       "      <td>Shared</td>\n",
       "      <td>2018-12-03 04:53:01.166</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.495611</td>\n",
       "      <td>16.916357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      distance cab_type     time_stamp       destination  \\\n",
       "9995      3.05     Uber  1543504379037            Fenway   \n",
       "9996      3.05     Uber  1543800477997            Fenway   \n",
       "9997      3.05     Uber  1543407083241            Fenway   \n",
       "9998      3.05     Uber  1544896813623            Fenway   \n",
       "9999      2.03     Lyft  1543812781166  Theatre District   \n",
       "\n",
       "                       source  price  surge_multiplier  \\\n",
       "9995            North Station   11.5               1.0   \n",
       "9996            North Station   26.0               1.0   \n",
       "9997            North Station   19.5               1.0   \n",
       "9998            North Station   36.5               1.0   \n",
       "9999  Northeastern University    7.0               1.0   \n",
       "\n",
       "                                        id  \\\n",
       "9995  934d2fbe-f978-4495-9786-da7b4dd21107   \n",
       "9996  af8fd57c-fe7c-4584-bd1f-beef1a53ad42   \n",
       "9997  b3c5db97-554b-47bf-908b-3ac880e86103   \n",
       "9998  fcb35184-9047-43f7-8909-f62a7b17b6cf   \n",
       "9999  7f0e8caf-e057-41eb-bdef-27eb14c88122   \n",
       "\n",
       "                                product_id       name                    date  \\\n",
       "9995  997acbb5-e102-41e1-b155-9df7de0a73f2   UberPool 2018-11-29 15:12:59.037   \n",
       "9996  6c84fd89-3f11-4782-9b50-97c468b19529      Black 2018-12-03 01:27:57.997   \n",
       "9997  6f72dfc5-27f1-42e8-84db-ccc7a75f6969     UberXL 2018-11-28 12:11:23.241   \n",
       "9998  6d318bcc-22a3-4af6-bddd-b409bfce1546  Black SUV 2018-12-15 18:00:13.623   \n",
       "9999                             lyft_line     Shared 2018-12-03 04:53:01.166   \n",
       "\n",
       "      month  hour  dayofweek  weekend  rush_hour  cab_freq  cab_type_mean  \n",
       "9995     11    15          3        0          1  0.504389      15.743446  \n",
       "9996     12     1          0        0          0  0.504389      15.743446  \n",
       "9997     11    12          2        0          0  0.504389      15.743446  \n",
       "9998     12    18          5        1          0  0.504389      15.743446  \n",
       "9999     12     4          0        0          0  0.495611      16.916357  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feat_eng(df):\n",
    "    # Define rush hour conditions\n",
    "    rush_hours = [6, 7, 8, 9, 15, 16, 17, 18]\n",
    "\n",
    "    #  initialize encoder\n",
    "    encoder = TargetEncoder()\n",
    "    return (df\n",
    "            .dropna()\n",
    "            .assign(date = pd.to_datetime(df['time_stamp']*(10**6)),\n",
    "                    month = lambda x: x['date'].dt.month,\n",
    "                    hour = lambda x: x['date'].dt.hour,\n",
    "                    dayofweek = lambda x: x['date'].dt.dayofweek,\n",
    "                    weekend = lambda x: np.where((x['dayofweek'] == 5) | (x['dayofweek'] == 6), 1, 0),\n",
    "                    rush_hour = lambda x: np.where((np.isin(x['hour'], \n",
    "                                                            rush_hours) & (x['weekend'] == 0)), 1, 0),\n",
    "                    cab_freq = lambda x: x.groupby('cab_type')['cab_type'].transform('count')/len(x),\n",
    "                    cab_type_mean = encoder.fit_transform(df['cab_type'], df['price'])\n",
    "                   )\n",
    "           )\n",
    "\n",
    "df_cabs = feat_eng(df)\n",
    "df_cabs.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a01b2e8-c813-479a-a01d-aaf914e80724",
   "metadata": {},
   "source": [
    "While one-hot encoding remains a standard and effective approach, exploring mean encoding can be beneficial, especially in complex datasets where this method might capture nuances in the data more effectively. Its use in Kaggle competitions underlines its potential for enhancing model performance.\n",
    "\n",
    "### Advancing Feature Engineering Techniques\n",
    "\n",
    "Feature engineering is a critical and ongoing process in data science, with potential for continuous improvement and innovation.\n",
    "\n",
    "#### Extended Techniques:\n",
    "- **Statistical Grouping**: Apply `groupby` to derive statistical measures from other columns. This can reveal insightful patterns based on categories.\n",
    "- **Encoding Geographical Data**: For categorical data like destinations or arrival points, consider converting to geographical coordinates (latitude and longitude). From these, calculate distances using methods like taxicab (Manhattan) distance or Vincenty distance, which considers the Earth's spherical shape.\n",
    "\n",
    "#### Kaggle Practices:\n",
    "- **Massive Feature Creation**: In Kaggle competitions, creating thousands of new features is common to enhance model accuracy, even if the improvements are marginal.\n",
    "- **Feature Selection**: Use techniques like `.feature_importances_` (from decision trees) to identify the most impactful features.\n",
    "- **Avoiding Redundancy**: Eliminate highly correlated features to ensure diversity in the data, enhancing the robustness of models.\n",
    "\n",
    "#### Dealing with Missing Data:\n",
    "- **Incorporating External Data**: In cases like a missing weather dataset for cab rides, you can independently research and integrate relevant external data (e.g., historical weather information).\n",
    "\n",
    "#### The Art of Feature Engineering:\n",
    "- **A Multifaceted Approach**: Effective feature engineering requires a blend of research, experimentation, and domain knowledge. It involves standardizing columns, assessing new features' impact on model performance, and ultimately selecting the most effective features.\n",
    "- **Continuous Exploration**: The techniques mentioned are just a fraction of the possibilities. Ongoing exploration and learning are key to mastering this aspect of data science.\n",
    "\n",
    "#### Moving Forward:\n",
    "Having understood these diverse strategies for feature engineering, the next step in the journey is building non-correlated ensembles, which focuses on combining diverse models to improve predictive performance.\n",
    "\n",
    "In summary, feature engineering is an expansive field requiring creativity, analytical skills, and a deep understanding of the data and the problem domain. It's a process of trial and improvement, where each new feature could potentially lead to a more robust and accurate model.\n",
    "\n",
    "### Building Non-Correlated Ensembles\n",
    "\n",
    "> \"In our final model, we had XGBoost as an ensemble model, which included 20 XGBoost models, 5 random forests, 6 randomized decision tree models, 3 regularized greedy forests, 3 logistic regression models, 5 ANN models, 3 elastic net models and 1 SVM model.\"\n",
    "> \n",
    "> â€“ [Song, Kaggle Winner](https://hunch243.rssing.com/chan-68612493/all_p1.html)\n",
    "\n",
    "Kaggle competitions' winning strategies often involve more than just a single machine learning model. The champions usually leverage an array of diverse models, forming what is known as an ensemble. However, these ensembles are not limited to standard boosting or bagging techniques like XGBoost or Random Forests. They are composite ensembles that integrate a variety of distinct models, which can include XGBoost, Random Forests, and other algorithms.\n",
    "\n",
    "In this discussion, our focus will be on creating such non-correlated ensembles. The goal is to blend multiple machine learning models in a way that maximizes accuracy and minimizes the risk of overfitting. This approach is a critical factor in achieving top performance in competitive machine learning environments.\n",
    "\n",
    "### Range of models\n",
    "\n",
    "The Wisconsin Breast Cancer dataset, used to predict whether a patient has breast cancer, has 569 rows and 30 columns and we can get the dataset from scikit learn's datasets.\n",
    "\n",
    "Assign the predictor columns to `X` and the target column to `y` by setting the `return_X_y=True` parameter:\n",
    "\n",
    "```python\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0bfd1e6-ee32-4d71-88e3-684d8b0713b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "# Prepare 5-fold cross-validation using StratifiedKFold for consistency\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79bcf0d8-8d31-4853-b04c-02263ff595d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_model(model):\n",
    "\n",
    "    scores = cross_val_score(model, X, y, cv=kfold)\n",
    "\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf2a3b27-6cf0-4f0f-9363-43e55d3ce052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9771619313771154"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_model(XGBClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b8de6ad-7002-4c08-9bfc-963b1e7f8d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4730321378667909"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_model(XGBClassifier(booster='gblinear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "113bc9e9-edb4-44ae-843e-c2fea3a23811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9683744760130415"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_model(XGBClassifier(booster='dart', one_drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500e484e-ad07-4f35-b520-8efd6d0d2b34",
   "metadata": {},
   "source": [
    "For the dart booster, we set `one_drop=True` to ensure that trees are actually dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9bba3e5a-b568-4b9e-8974-5469ddad2de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666356155876418"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_model(RandomForestClassifier(random_state=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06e13c88-703d-43ab-9c03-d1540960bc2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9508150908244062"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_model(LogisticRegression(max_iter=10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec4d82c-fdd0-4d29-b95f-752d162e4aba",
   "metadata": {},
   "source": [
    "From our choice set of models, we can see good performances overall except for the XGBoost with `dart` as a booster. We will not continue with it to the next phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b722225c-0413-4360-b230-9adae7be53cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9701133364384411"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_model(XGBClassifier(max_depth=2, n_estimators=500, learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86362cf-f415-487f-a553-19732398b350",
   "metadata": {},
   "source": [
    "Now that we have a small set of models, we will now turn our attention to the issue of correlations.\n",
    "\n",
    "### Understanding and Applying Correlation in Machine Learning Ensembles\n",
    "\n",
    "#### **1. Introduction to Correlation**\n",
    "- **Definition**: Correlation is a statistical metric ranging from -1 to 1, representing the strength of a linear relationship between two datasets.\n",
    "  - **Correlation of 1**: Indicates a perfect linear relationship (a straight line).\n",
    "  - **Correlation of 0**: No linear relationship is evident.\n",
    "- **Visual Examples**:\n",
    "  - *Listed Correlations*: Visuals show that higher correlations align points closer to a straight line.\n",
    "  - *Anscombe's Quartet*: Demonstrates how datasets with identical correlations (0.816 in this case) can display vastly different distributions. This illustrates that correlation provides useful information but doesn't fully describe the data relationship.\n",
    "\n",
    "#### **2. Correlation in Machine Learning Ensembles**\n",
    "- **Goal**: To select non-correlated models for the ensemble.\n",
    "- **Why Avoid High Correlation?**\n",
    "  - If two models in an ensemble yield identical predictions, the second model doesn't add value. \n",
    "  - Ensembles benefit from diversity in model predictions. High correlation suggests similar predictions, reducing the ensemble's effectiveness.\n",
    "- **Majority Rules Context**: In an ensemble using majority rules, a prediction is only incorrect if most models err. Therefore, having models that perform well individually but differ in their predictions (low correlation) is advantageous.\n",
    "- **How to Compute Model Correlations**:\n",
    "  - Obtain predictions from different models.\n",
    "  - Merge these predictions into a DataFrame.\n",
    "  - Utilize the `.corr` method in the DataFrame to calculate correlations between model predictions, enabling the identification of non-correlated, diverse models for the ensemble.\n",
    "\n",
    "The focus here is not on selecting all possible models but on choosing those that offer diverse, non-correlated insights, essential for a robust machine learning ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2278d115-71c3-4773-a4cf-fc0b9c47bbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_pred(model):\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    score = accuracy_score(y_pred, y_test)\n",
    "\n",
    "    print(score)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85e855e6-fce2-424f-8fb5-0d7183c0f75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea1e5eea-41df-4a06-9c22-62e783c8d924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9790209790209791\n"
     ]
    }
   ],
   "source": [
    "y_pred_gbtree = y_pred(XGBClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e35c6c84-5146-433a-bc66-a0e36c399175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9790209790209791\n"
     ]
    }
   ],
   "source": [
    "y_pred_dart = y_pred(XGBClassifier(booster='dart', one_drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7aa41b1-1b60-40e3-a00f-5a59b314cf00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.993006993006993\n"
     ]
    }
   ],
   "source": [
    "y_pred_forest = y_pred(RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "306c0f18-925a-41a3-8b88-3db6ea5eb4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9790209790209791\n"
     ]
    }
   ],
   "source": [
    "y_pred_logistic = y_pred(LogisticRegression(max_iter=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ac29133-a33b-45d2-8ea5-cb02be5893ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.986013986013986\n"
     ]
    }
   ],
   "source": [
    "y_pred_xgb = y_pred(XGBClassifier(max_depth=2, n_estimators=500, learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7ef428-d88e-4fff-af74-1cc1cf7ab0cd",
   "metadata": {},
   "source": [
    "We will next concatenate the predictions into a new DataFrame using `np.c` and run correlations on the DataFrame using the `.corr()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52b4bc76-9444-4979-a4b7-12f604a13960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gbtree</th>\n",
       "      <th>dart</th>\n",
       "      <th>forest</th>\n",
       "      <th>logistic</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gbtree</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967574</td>\n",
       "      <td>0.936398</td>\n",
       "      <td>0.984011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dart</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967574</td>\n",
       "      <td>0.936398</td>\n",
       "      <td>0.984011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest</th>\n",
       "      <td>0.967574</td>\n",
       "      <td>0.967574</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968456</td>\n",
       "      <td>0.984011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic</th>\n",
       "      <td>0.936398</td>\n",
       "      <td>0.936398</td>\n",
       "      <td>0.968456</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>0.984011</td>\n",
       "      <td>0.984011</td>\n",
       "      <td>0.984011</td>\n",
       "      <td>0.952321</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            gbtree      dart    forest  logistic       xgb\n",
       "gbtree    1.000000  1.000000  0.967574  0.936398  0.984011\n",
       "dart      1.000000  1.000000  0.967574  0.936398  0.984011\n",
       "forest    0.967574  0.967574  1.000000  0.968456  0.984011\n",
       "logistic  0.936398  0.936398  0.968456  1.000000  0.952321\n",
       "xgb       0.984011  0.984011  0.984011  0.952321  1.000000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred = pd.DataFrame(data= np.c_[y_pred_gbtree, y_pred_dart, \n",
    "                       y_pred_forest, y_pred_logistic, y_pred_xgb], \n",
    "                       columns=['gbtree', 'dart','forest', 'logistic', 'xgb'])\n",
    "\n",
    "df_pred.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3b05ea-10d6-47c4-8615-69934be50368",
   "metadata": {},
   "source": [
    "1. **Correlation Among Models**: In ensemble learning, it's common to check the correlation among different models' predictions. A lower correlation between models generally indicates that they are capturing different aspects of the data, which can be beneficial in an ensemble. The diagonal showing a correlation of 1.0 simply reflects that any model is perfectly correlated with itself.\n",
    "\n",
    "2. **Selecting Non-Correlated Models**: There's no absolute threshold for what constitutes \"non-correlated\" in this context. The idea is to select models that are less correlated with each other to maximize the diversity of the ensemble. In our case, after the XGBoost model (`xgb`), the next least correlated models are the random forest and logistic regression.\n",
    "\n",
    "3. **Using VotingClassifier**: This is a technique in ensemble learning where multiple models are combined to make predictions. Each model in the ensemble votes for a class, and the class receiving the majority of the votes is chosen as the final prediction. The `VotingClassifier` in Python's `sklearn` library is a straightforward way to implement this.\n",
    "\n",
    "#### Understanding the VotingClassifier Ensemble in Scikit-learn\r\n",
    "The VotingClassifier ensemble in Scikit-learn is crafted to amalgamate several classification models. It operates on the principle of majority voting to determine the final output for each prediction. It's important to note that scikit-learn provides a similar tool for regression tasks, named VotingRegressor. This regressor works by averaging the outputs of various regression models.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9766d6a-5e98-4636-a6f3-bac23d57f7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666200900481291\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list:\n",
    "estimators = []\n",
    "\n",
    "# Initialize the first model:\n",
    "logistic_model = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# Append the model to the list as a tuple in the form (model_name, model):\n",
    "estimators.append(('logistic', logistic_model))\n",
    "\n",
    "# Repeat steps 2 and 3 as many times as desired:\n",
    "xgb_model = XGBClassifier(max_depth=2, n_estimators=500, learning_rate=0.1)\n",
    "\n",
    "estimators.append(('xgb', xgb_model))\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=43)\n",
    "\n",
    "estimators.append(('rf', rf_model))\n",
    "\n",
    "# Initialize VotingClassifier (or VotingRegressor) using the list of models as input:\n",
    "ensemble = VotingClassifier(estimators)\n",
    "\n",
    "# Score the classifier using cross_val_score:\n",
    "scores = cross_val_score(ensemble, X, y, cv=kfold)\n",
    "\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2eb467-efb7-4733-8315-cd137574c19d",
   "metadata": {},
   "source": [
    "We took out time to do this step by step. We will now take our time to create a function that would accomplish all of these into one for automation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22ae428d-c971-4914-9dc3-ea4ebb43081b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def evaluate_ensemble(models, X, y, cv):\n",
    "    \"\"\"\n",
    "    Create and evaluate an ensemble model using VotingClassifier.\n",
    "\n",
    "    Parameters:\n",
    "    models (list of tuples): A list of tuples where each tuple contains the model name as a string \n",
    "                             and the model instance.\n",
    "    X: Feature set.\n",
    "    y: Target variable.\n",
    "    cv: Cross-validation splitting strategy.\n",
    "\n",
    "    Returns:\n",
    "    float: The mean score of the ensemble model.\n",
    "    \"\"\"\n",
    "    # Initialize an empty list for estimators\n",
    "    estimators = []\n",
    "\n",
    "    # Iterate over the provided models, initializing and adding them to the estimators list\n",
    "    for model_name, model in models:\n",
    "        estimators.append((model_name, model))\n",
    "\n",
    "    # Initialize VotingClassifier using the list of models\n",
    "    ensemble = VotingClassifier(estimators)\n",
    "\n",
    "    # Score the classifier using cross_val_score\n",
    "    scores = cross_val_score(ensemble, X, y, cv=cv)\n",
    "\n",
    "    # Return the mean of the scores\n",
    "    return scores.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d1be4e1-3b85-499c-a34e-a2e8f81fbc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666200900481291\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Your models configurations\n",
    "models = [\n",
    "    ('logistic', LogisticRegression(max_iter=10000)),\n",
    "    ('xgb', XGBClassifier(max_depth=2, n_estimators=500, learning_rate=0.1)),\n",
    "    ('rf', RandomForestClassifier(random_state=43))\n",
    "]\n",
    "\n",
    "# Example usage\n",
    "mean_score = evaluate_ensemble(models, X, y, kfold)\n",
    "print(mean_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587f3b79-22fc-4806-8c7c-1ddac23ff382",
   "metadata": {},
   "source": [
    "### Stacking\n",
    "\n",
    "Stacking is a powerful technique in machine learning, often utilized by Kaggle competition winners for its effectiveness. David Austin, a Kaggle winner, notably mentioned his preference for xgboost for stacking and boosting in an interview with PyImageSearch:\n",
    "\n",
    "> \"For stacking and boosting I use xgboost, again primarily due to familiarity and its proven results.\" (Source: [PyImageSearch Interview with David Austin](https://www.pyimagesearch.com/2018/03/26/interview-david-austin-1st-place-25000-kaggles-popular-competition/)).\n",
    "\n",
    "**Understanding Stacking:**\n",
    "Stacking is a method that involves two levels of machine learning models. The first level consists of base models that make predictions on the dataset. The second, or meta level, uses these predictions as its input to generate the final output. Unlike traditional models, the final model in a stacking approach does not use the original data directly but rather the outputs of the base models.\n",
    "\n",
    "**Success in Competitions:**\n",
    "Stacked models are a common strategy in Kaggle competitions. Competitions often have deadlines for mergers, allowing individuals and teams to combine their efforts. This collaboration is beneficial in stacking as it enables the creation of more robust ensembles and the combination of diverse models, enhancing performance.\n",
    "\n",
    "**Distinctive Feature of Stacking:**\n",
    "The key differentiator of stacking from other ensemble methods is the meta-model. This model combines predictions from base models. For regression tasks, linear regression is commonly used as the meta-model, while logistic regression is a typical choice for classification tasks.\n",
    "\n",
    "**Implementing Stacking in scikit-learn:**\n",
    "Scikit-learn simplifies the implementation of stacking with its stacking regressor and classifier. The process mirrors the ensemble approach: selecting various base models and then using a linear or logistic regression model as the meta-model. This structured approach in scikit-learn streamlines stacking, making it accessible for various machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a20db2cc-6e7f-430e-9a23-e4d2012c0a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9789318428815401\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list of base models:\n",
    "base_models = []\n",
    "\n",
    "# Append all base models to the base model list as tuples using the syntax (name, model):\n",
    "base_models.append(('lr', LogisticRegression()))\n",
    "base_models.append(('xgb', XGBClassifier()))\n",
    "base_models.append(('rf', RandomForestClassifier(random_state=2)))\n",
    "\n",
    "# Choose a meta model, preferably linear regression for regression and logistic regression for classification:\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Initialize StackingClassifier (or StackingRegressor) using base_models for estimators and meta_model for final_estimator:\n",
    "clf = StackingClassifier(estimators=base_models, final_estimator=meta_model)\n",
    "\n",
    "# Validate the stacked model using cross_val_score or any other scoring method:\n",
    "scores = cross_val_score(clf, X, y, cv=kfold)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0d9f25-8938-493a-b7ad-4bd037b2380a",
   "metadata": {},
   "source": [
    "This is the strongest result yet.\r\n",
    "\r\n",
    "As you can see, stacking is an incredibly powerful method and outperformed the non-correlated ensemble from the previous sectio\n",
    "\n",
    "n. e now create a function to handle it all for both classification and regression mode then we download models from scikit learn to test the function outls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "01db9dc3-05d8-4edb-a4c9-f0a66c20d383",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import StackingClassifier, StackingRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def create_stacked_model(base_models, task_type, X, y, cv):\n",
    "    \"\"\"\n",
    "    Create and validate a stacked model for classification or regression.\n",
    "\n",
    "    :param base_models: List of tuples (name, model instance).\n",
    "    :param task_type: 'classification' or 'regression'.\n",
    "    :param X: Feature data.\n",
    "    :param y: Target data.\n",
    "    :param cv: Cross-validation strategy.\n",
    "    :return: Mean cross-validation score of the stacked model.\n",
    "    \"\"\"\n",
    "    # Choose meta model based on task type\n",
    "    if task_type == 'classification':\n",
    "        meta_model = LogisticRegression()\n",
    "        StackingModel = StackingClassifier\n",
    "    elif task_type == 'regression':\n",
    "        meta_model = LinearRegression()\n",
    "        StackingModel = StackingRegressor\n",
    "    else:\n",
    "        raise ValueError(\"task_type must be 'classification' or 'regression'\")\n",
    "\n",
    "    # Initialize Stacking Model\n",
    "    stacked_model = StackingModel(estimators=base_models, final_estimator=meta_model)\n",
    "\n",
    "    # Validate the model\n",
    "    scores = cross_val_score(stacked_model, X, y, cv=cv)\n",
    "    return scores.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b850bf1-12f2-481a-841a-753ad3e3e1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV Score for Classification: 0.9066666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Example data (Iris dataset)\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Define base models\n",
    "base_models = [\n",
    "    ('lr', LogisticRegression()),\n",
    "    ('rf', RandomForestClassifier(random_state=2)),\n",
    "    ('xgb', XGBClassifier())\n",
    "]\n",
    "\n",
    "# Cross-validation strategy\n",
    "kfold = KFold(n_splits=5)\n",
    "\n",
    "# Call the function for a classification task\n",
    "mean_score = create_stacked_model(base_models, 'classification', X, y, kfold)\n",
    "print(f\"Mean CV Score for Classification: {mean_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9336aa6-21c8-406d-95fb-dc6865be3c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV Score for Regression: 0.6795318996485826\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Fetch the California housing dataset\n",
    "california_housing = fetch_california_housing()\n",
    "X, y = california_housing.data, california_housing.target\n",
    "\n",
    "# Define base models for regression\n",
    "base_models = [\n",
    "    ('ridge', Ridge()),\n",
    "    ('rf', RandomForestRegressor(random_state=2)),\n",
    "    ('xgb', XGBRegressor())\n",
    "]\n",
    "\n",
    "# Cross-validation strategy\n",
    "kfold = KFold(n_splits=5)\n",
    "\n",
    "# Call the function for a regression task\n",
    "mean_score = create_stacked_model(base_models, 'regression', X, y, kfold)\n",
    "print(f\"Mean CV Score for Regression: {mean_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cab5043-4686-4371-987f-865502ebe685",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
