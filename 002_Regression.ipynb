{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f0cab83-0b5b-4d32-8cc7-e69ef21f7500",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;\">Regression</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a0a164-9686-4622-b190-a4aeaffb0708",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Regression analysis is a statistical process that helps us understand the relationship between a dependent variable and one or more independent variables. The dependent variable is the thing we want to predict or understand better, and the independent variables are the things that we think might be related to the dependent variable. For example, if we want to predict the price of a house based on some of its features like size, location, number of bedrooms etc. We can employ a regression analysis to understand how these features of a particular house affects its price. In this case, the dependent variable is the price of the house, and the independent variables are the features.\r\n",
    "\r\n",
    "The relationship between the independent variables and the dependent variable is always explained mathematically because it helps us understand how strong or weak the relationship is. We use mathematical formulas to find the best possible mapping between the independent variables and the dependent variable. This mapping can then be used to predict the value of the dependent variable for new values of the independent variable\n",
    "\n",
    "Machine learning algorithms aim to predict the values of one output column, (called the target vector and denoted by small $y$), using data from one or more input columns (or the feature matrix, denoted with capital $X$). The predictions rely on mathematical equations determined by the general class of machine learning problems being addressed.\n",
    "\n",
    "The most common regression algorithm is linear regression. Linear regression takes each column that makes up the feature matrix as a polynomial variable and multiplies the values by coefficients (also called weights) to predict the target column. Gradient descent works under the hood to minimize the error. The predictions of linear regression could be any real number.\n",
    "\n",
    "In the bike rentals dataset we worked on in the last section, `'cnt'` is the number of bike rentals in a given day. Predicting this column would be of great use to a bike rental company. We will denote this as our target vector $y$.\n",
    "\n",
    "Our mission (should we accept) would be to predict the correct number of bike rentals on a given day based on data such as whether this day is a holiday or working day, forecasted temperature, humidity, windspeed, and so on (our feature matrix $X$).\n",
    "\n",
    "ion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d21cf2-937a-4d8d-aadb-96f1db5b0a44",
   "metadata": {},
   "source": [
    "## Declaring predictor and target columns\n",
    "\n",
    "Machine learning works by performing mathematical operations on each of the predictor columns or feature matrix to determine the target vector.\n",
    "\n",
    "Let's import our libraries, including our data_wrangle so we can get our data ready for this next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2916db6-6132-4331-af49-9e444bd80faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from data_wrangle import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31a3f22b-9617-4e29-b898-8a381c8c1521",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/theAfricanQuant/XGBoost4machinelearning/main/data/bike_rentals.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b318de8a-4f06-4008-bc81-5f98cd150989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>331</td>\n",
       "      <td>654</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>131</td>\n",
       "      <td>670</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>120</td>\n",
       "      <td>1229</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>108</td>\n",
       "      <td>1454</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>82</td>\n",
       "      <td>1518</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season   yr  mnth  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01     1.0  0.0   1.0      0.0      6.0         0.0   \n",
       "1        2  2011-01-02     1.0  0.0   1.0      0.0      0.0         0.0   \n",
       "2        3  2011-01-03     1.0  0.0   1.0      0.0      1.0         1.0   \n",
       "3        4  2011-01-04     1.0  0.0   1.0      0.0      2.0         1.0   \n",
       "4        5  2011-01-05     1.0  0.0   1.0      0.0      3.0         1.0   \n",
       "\n",
       "   weathersit      temp     atemp       hum  windspeed  casual  registered  \\\n",
       "0           2  0.344167  0.363625  0.805833   0.160446     331         654   \n",
       "1           2  0.363478  0.353739  0.696087   0.248539     131         670   \n",
       "2           1  0.196364  0.189405  0.437273   0.248309     120        1229   \n",
       "3           1  0.200000  0.212122  0.590435   0.160296     108        1454   \n",
       "4           1  0.226957  0.229270  0.436957   0.186900      82        1518   \n",
       "\n",
       "    cnt  \n",
       "0   985  \n",
       "1   801  \n",
       "2  1349  \n",
       "3  1562  \n",
       "4  1600  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_data(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab6d9459-f297-4cd0-a152-b3748ee45cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>727</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.254167</td>\n",
       "      <td>0.226642</td>\n",
       "      <td>0.652917</td>\n",
       "      <td>0.350133</td>\n",
       "      <td>2114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>728</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.255046</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.155471</td>\n",
       "      <td>3095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>729</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.242400</td>\n",
       "      <td>0.752917</td>\n",
       "      <td>0.124383</td>\n",
       "      <td>1341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.255833</td>\n",
       "      <td>0.231700</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.350754</td>\n",
       "      <td>1796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>731</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.215833</td>\n",
       "      <td>0.223487</td>\n",
       "      <td>0.577500</td>\n",
       "      <td>0.154846</td>\n",
       "      <td>2729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>731 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     instant  season   yr  mnth  holiday  weekday  workingday  weathersit  \\\n",
       "0          1     1.0  0.0     1      0.0      6.0         0.0           2   \n",
       "1          2     1.0  0.0     1      0.0      0.0         0.0           2   \n",
       "2          3     1.0  0.0     1      0.0      1.0         1.0           1   \n",
       "3          4     1.0  0.0     1      0.0      2.0         1.0           1   \n",
       "4          5     1.0  0.0     1      0.0      3.0         1.0           1   \n",
       "..       ...     ...  ...   ...      ...      ...         ...         ...   \n",
       "726      727     1.0  1.0    12      0.0      4.0         1.0           2   \n",
       "727      728     1.0  1.0    12      0.0      5.0         1.0           2   \n",
       "728      729     1.0  1.0    12      0.0      6.0         0.0           2   \n",
       "729      730     1.0  1.0    12      0.0      0.0         0.0           1   \n",
       "730      731     1.0  1.0    12      0.0      1.0         0.0           2   \n",
       "\n",
       "         temp     atemp       hum  windspeed   cnt  \n",
       "0    0.344167  0.363625  0.805833   0.160446   985  \n",
       "1    0.363478  0.353739  0.696087   0.248539   801  \n",
       "2    0.196364  0.189405  0.437273   0.248309  1349  \n",
       "3    0.200000  0.212122  0.590435   0.160296  1562  \n",
       "4    0.226957  0.229270  0.436957   0.186900  1600  \n",
       "..        ...       ...       ...        ...   ...  \n",
       "726  0.254167  0.226642  0.652917   0.350133  2114  \n",
       "727  0.253333  0.255046  0.590000   0.155471  3095  \n",
       "728  0.253333  0.242400  0.752917   0.124383  1341  \n",
       "729  0.255833  0.231700  0.483333   0.350754  1796  \n",
       "730  0.215833  0.223487  0.577500   0.154846  2729  \n",
       "\n",
       "[731 rows x 13 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bikes = prep_data(df)\n",
    "df_bikes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be8a172-2706-468d-873b-ceb4ca66e1a7",
   "metadata": {},
   "source": [
    "We start by creating a new variable called `target` and assign the name of the target vector column to it. Then we create a another variable called `features` and using list comprehension, we assign the rest of the columns name (except the target) to it. \n",
    "\n",
    "I think the next lines of code are self explanatory. There are other ways of accomplishing this step. i just love practicing my list comprehensions whenever I get the chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3d22dec-84b8-49ff-b83b-2ef5b48515a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'cnt'\n",
    "features = [cols for cols in df_bikes.columns if cols not in target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f254ccc3-9e13-45ed-b28e-15ccf8bb2695",
   "metadata": {},
   "source": [
    "We next separate our data into the target vector, $y$ and the feature matrix $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5e91876-c7ba-4952-b425-51dd0f6c192a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of target vector, y: (731,)\n",
      "shape of feature matrix, X: (731, 12)\n"
     ]
    }
   ],
   "source": [
    "y = df_bikes[target]\n",
    "X = df_bikes[features]\n",
    "print(f\"shape of target vector, y: {y.shape}\")\n",
    "print(f\"shape of feature matrix, X: {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6702a3e9-1d6c-4678-ad43-9dd1a0e28652",
   "metadata": {},
   "source": [
    "Everything up to this point looks okay.\n",
    "\n",
    "Before running linear regression, we must split the data into a training set and a test set. The training set fits the data to the algorithm, using the target column to minimize the error. After a model is built, it's scored against the test data. \n",
    "\n",
    "## Accessing scikit-learn\n",
    "\n",
    "We will allow scikit-learn to handle all our machine learning libraries. We will i\n",
    "Impor`t train_test_spl`it an`d LinearRegressi`on fro`m scikit-lea`.s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49729543-c3b5-4bee-8f62-eba8e7ec6ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912ec227-0be5-4946-9330-419a87d61e87",
   "metadata": {},
   "source": [
    "We now split the data into the training set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b8106d6-2a8a-4e57-8b52-efcdbfa9486b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6b3278-0f37-4ebb-b2ac-66a2fc0790df",
   "metadata": {},
   "source": [
    "The `random_state` parameter is called here so as to ensure that when next we or another person checks out our code and runs the codes, the same set of data that we randomly selected on this run will also be selected as long as we are using exactly the same dataset. Any number choses is okay as long as it is used again when re-runing the codes. I chose the number 43 because that was the age I was when I started learning data science in 2017.\n",
    "\n",
    "## Modeling linear regression\n",
    "\n",
    "A linear regression model may be built with the following steps:\n",
    "\n",
    "1. We initialize the machine learning model. We do so by instantiating the model and storing it to a variable name of our choosing.\n",
    "2. Fit the model on the training set. This is where the machine learning model is built. Note that `X_train` is the feature matrix and `y_train` is the target vector. The machine learning tries to assign weights that it feels bewst represents how tp get the values in the target vector from the values in the feature matrix.\n",
    "3. Make predictions for the test set. we store the predictions of `X_test`, or the feature matrix of the test set, in the variable `y_pred` using the `.predict` method on lin_reg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d67b78e0-5571-4774-bb12-887a7319fe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "y_pred = lin_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2b2e19-7b57-4f5b-80f8-9d57766a56af",
   "metadata": {},
   "source": [
    "The `y_pred` (called $y$-$hat$ in Statistics) above contains our predicted values. Our next step is to compare the values with that of the original target vector of the test set or `y_test`. we calculate the error from the difference between the values. The standard for linear regression is the root mean squared error (RMSE), which is the sum of the squares of differences between predicted and actual values, and the square root, to keep the units the same.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b38c24a-bb13-4e38-bbf9-e22f8c191cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "005ed9aa-a13f-4b4f-95b7-490c3c36ac78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 969.77\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"RMSE: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7df071-9b2c-42a7-a297-2b900e1b718d",
   "metadata": {},
   "source": [
    "For us to determine if the value we got is good or bad, we'd need to know the expected range of rentals per day. The .describe() method may be used on the `'cnt'` column to see that range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb1c04e2-79c8-4e4b-8506-96ab2479472b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     731.000000\n",
       "mean     4504.348837\n",
       "std      1937.211452\n",
       "min        22.000000\n",
       "25%      3152.000000\n",
       "50%      4548.000000\n",
       "75%      5956.000000\n",
       "max      8714.000000\n",
       "Name: cnt, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bikes['cnt'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab891ac-2899-4af6-a178-2383691c37f6",
   "metadata": {},
   "source": [
    "Our value doesn't look bad at all. Especially seeing the mean and also the standard deviation. However, we are going to try a different model to see if we could further reduce this RMSE value.\n",
    "\n",
    "## XGBRegressor\n",
    "\n",
    "We will now import the `XGBRegressor` and repeat the exact same steps we took with the `LinearRegressor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "530e6079-4ab6-4640-9432-e5de7c23eac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6143c319-e81e-4d11-a295-c13de6cae94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg = XGBRegressor()\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "y_pred = xgb_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2eb77b49-1012-4173-8edd-3326e88217cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 702.00\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"RMSE: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8b6260-a7af-438d-a4b0-2d98691dd2e2",
   "metadata": {},
   "source": [
    "Our performance has improved significantly with the XGBRegressor.\n",
    "\n",
    "One thing we should note is that fact that splitting the data into a training set and a test set is arbitrary, and a different number chosen as `random_state` will give a different RMSE. So depending one one value like we did above is not going to be a reliable source for a robust model. You couls try it with a different random number.\n",
    "\n",
    "## Cross-validation\n",
    "\n",
    "Since different splits would tend to give different answer, we will need to find a way to address this issues: We will use k-fold cross validation. What this does is to split the data multiple times into different training sets and test sets, and then to take the mean of the scores. The number of splits, called folds, is denoted by $k$. It's standard to use k = 3, 4, 5, or 10 splits.\n",
    "\n",
    "Cross-validation works by fitting a machine learning model on the first training set and scoring it against the first test set, and then repeating the process again and again based on  the number of folds.\n",
    "\n",
    "Five folds is standard because $20\\%$ of the test set is held back each time. With $10$ folds, only $10\\%$ of the data is held back; however, $90\\%$ of the data is available for training and the mean is less vulnerable to outliers. For a smaller datatset, three folds may work better.\n",
    "\n",
    "At the end, there will be $k$ different scores evaluating the model against $k$ different test sets. Taking the mean score of the $k$ folds gives a more reliable score than any single fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26e83b90-d3a1-420c-8448-d6937f720815",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf9e0c0-42b9-4804-9444-acf0221463ce",
   "metadata": {},
   "source": [
    "We will now try thos out with the LinearRegressor. The way it works this time around is for us to drop the entire feature matrix $X$ and the target vector $y$ into the `cross_val_score`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69df7f3c-459c-4c81-ab21-8e58805b611d",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08654467-3a4e-4b10-80f6-1b1779a0c2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "scores = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eab9640-b378-45d4-828a-f56a7aa63647",
   "metadata": {},
   "source": [
    "In the above, we chose the value of our cv parameter to be 10 and that for scoring to be `'neg_mean_squared_error'`. Scikit-learn is designed to select the highest score when training models, which might work well when we are seeking for accuracy, but not for errors when the lowest is best. By taking the negative of each mean squared error, the lowest ends up being the highest. To get our values in the positive, we will find the square root of the our final values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "913ee7ab-a9fb-4d3f-be25-b7b5e48c51d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reg rmse: [ 504.01  840.55 1140.88  728.39  640.2   969.95 1133.45 1252.85 1084.64\n",
      " 1425.33]\n",
      "RMSE mean: 972.0234147419287\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(-scores)\n",
    "\n",
    "print(f'Reg rmse: {np.round(rmse, 2)}')\n",
    "\n",
    "print(f'RMSE mean: {rmse.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bf03d4-b2a9-4b17-82d4-7793199f53f9",
   "metadata": {},
   "source": [
    "LinearRegression performed better this time than it did the first time. The point here is not whether the score is better or worse. The point is that it's a better estimation of how linear regression will perform on unseen data.\n",
    "\n",
    "Using cross-validation is always recommended for a better estimate of the score.\n",
    "\n",
    "### XGBoost\n",
    "\n",
    "Let us repeat the same steps as above now with the XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d088cd7-d4b7-4676-b854-6796c5aaac18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reg rmse: [ 717.65  692.8   520.7   737.68  835.96 1006.24  991.34  747.61  891.99\n",
      " 1731.13]\n",
      "RMSE mean: 887.3099729285601\n"
     ]
    }
   ],
   "source": [
    "model = XGBRegressor()\n",
    "scores = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=10)\n",
    "\n",
    "rmse = np.sqrt(-scores)\n",
    "\n",
    "print(f'Reg rmse: {np.round(rmse, 2)}')\n",
    "\n",
    "print(f'RMSE mean: {rmse.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee1bc7f-9bac-4604-8505-ffd56f2ce328",
   "metadata": {},
   "source": [
    "XGBoost wins again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874d90d6-12ec-477f-9fe4-a59f47f93999",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
