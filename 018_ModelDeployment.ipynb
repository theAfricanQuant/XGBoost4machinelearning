{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b3a1ed3-71d8-4a1e-bc3d-0f4a59ae41c5",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;\">Model Deployment</h1>\n",
    "\n",
    "\r\n",
    "#### Overview\r\n",
    "In this notebook focused on XGBoost, we integrate several concepts to develop a machine learning model suitable for industrial applications. Unlike academic or competition settings, industrial models prioritize automation due to the frequent influx of new data. The process involves more structured procedures, placing less emphasis on minor performance enhancements through model tweaking.\r\n",
    "\r\n",
    "#### Key Learning Areas\r\n",
    "- **One-Hot Encoding and Sparse Matrices**: Essential techniques for handling categorical data.\r\n",
    "- **Customizing Scikit-learn Transformers**: Enhancing automated workflows in machine learning pipelines.\r\n",
    "- **Finalizing an XGBoost Model**: Preparing the model for real-world applications.\r\n",
    "- **Building a Machine Learning Pipeline**: Constructing an end-to-end process for handling incoming data, accommodating both categorical and numericalhapter10).\r\n",
    "\r\n",
    "#### Encoding Mixed Data: Case Study\r\n",
    "Imagine working for an EdTech company with the task of predicting student grades to tailor tech skill-building services. The initial step involves loading and processing mixed data (numerical and categorical) related to student grades using pandas.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "**Explanation of Key Terms:**\r\n",
    "- **One-Hot Encoding**: A process to convert categorical data into a format that can be fed to machine learning algorithms. It creates new columns indicating the presence of each possible value from the original data.\r\n",
    "- **Sparse Matrices**: Efficient storage format for matrices with a lot of zeros. Useful in handling large, one-hot encoded data.\r\n",
    "- **Scikit-learn Transformers**: Tools in scikit-learn for transforming data before feeding it into a model. Customizing these allows for more tailored data preprocessing.\r\n",
    "- **XGBoost**: A powerful machine learning algorithm known for its speed and performance, particularly with structured data.\r\n",
    "- **Machine Learning Pipeline**: An automated process that includes steps like data preprocessing, model training, and making predictions. It ensures consistency and efficiency in model deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e9fc6933-ded7-43d2-8949-5b545b629812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV,  train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from helper_file import *\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31a51a98-145c-426d-9364-86716a3c4849",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('data')\n",
    "\n",
    "# Create a data folder if it doesn't exist\n",
    "if not data_dir.exists():\n",
    "    data_dir.mkdir()\n",
    "\n",
    "# File path for saving, using the Path object\n",
    "file_path = data_dir / 'student-por.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba410cd0-50b7-40c0-a9c0-8c07931f1d52",
   "metadata": {},
   "source": [
    "The data contained herein is separated by semi-colons. CSV stands for Comma-Separated Values, not Semi-Colon-Separated Values. However, pandas comes with a `sep` parameter, which stands for separator, that may be set to the semi-colon, (;), as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "310a8a2f-d322-4616-a8e3-8cd84b199b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15.0</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15.0</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16.0</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school  sex   age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  \\\n",
       "0     GP  NaN  18.0       U     GT3       A     4     4  at_home   teacher   \n",
       "1     GP    F   NaN       U     GT3       T     1     1  at_home     other   \n",
       "2     GP    F  15.0       U     LE3       T     1     1  at_home     other   \n",
       "3     GP    F  15.0       U     GT3       T     4     2   health  services   \n",
       "4     GP    F  16.0       U     GT3       T     3     3    other     other   \n",
       "\n",
       "   ... famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
       "0  ...      4        3      4     1     1      3        4   0  11  11  \n",
       "1  ...      5        3      3     1     1      3        2   9  11  11  \n",
       "2  ...      4        3      2     2     3      3        6  12  13  12  \n",
       "3  ...      3        2      2     1     1      5        0  14  14  14  \n",
       "4  ...      4        3      2     1     2      5        0  11  13  13  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(file_path, sep=';')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebb5b4a-4a10-459c-845d-ceba149bdeab",
   "metadata": {},
   "source": [
    "### Clearing null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e13be5ae-3461-4e49-8b7a-faeab8686bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_nulls(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5968fae1-0cc5-4aab-835f-37fa8c224672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school  sex   age address famsize Pstatus  Medu  Fedu     Mjob     Fjob  \\\n",
       "0     GP  NaN  18.0       U     GT3       A     4     4  at_home  teacher   \n",
       "1     GP    F   NaN       U     GT3       T     1     1  at_home    other   \n",
       "\n",
       "   ... famrel freetime  goout  Dalc  Walc health absences G1  G2  G3  \n",
       "0  ...      4        3      4     1     1      3        4  0  11  11  \n",
       "1  ...      5        3      3     1     1      3        2  9  11  11  \n",
       "\n",
       "[2 rows x 33 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_nulls(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cfcc7e8-7456-4ae9-be8c-51b8aba90a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to see all the columns\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3aa89af-2e08-44f9-91a1-e6181e20f4d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>reason</th>\n",
       "      <th>guardian</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>schoolsup</th>\n",
       "      <th>famsup</th>\n",
       "      <th>paid</th>\n",
       "      <th>activities</th>\n",
       "      <th>nursery</th>\n",
       "      <th>higher</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>course</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>course</td>\n",
       "      <td>father</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  school  sex   age address famsize Pstatus  Medu  Fedu     Mjob     Fjob  \\\n",
       "0     GP  NaN  18.0       U     GT3       A     4     4  at_home  teacher   \n",
       "1     GP    F   NaN       U     GT3       T     1     1  at_home    other   \n",
       "\n",
       "   reason guardian  traveltime  studytime  failures schoolsup famsup paid  \\\n",
       "0  course      NaN           2          2         0       yes     no   no   \n",
       "1  course   father           1          2         0        no    yes   no   \n",
       "\n",
       "  activities nursery higher internet romantic  famrel  freetime  goout  Dalc  \\\n",
       "0         no     yes    yes       no       no       4         3      4     1   \n",
       "1         no      no    yes      yes       no       5         3      3     1   \n",
       "\n",
       "   Walc  health  absences  G1  G2  G3  \n",
       "0     1       3         4   0  11  11  \n",
       "1     1       3         2   9  11  11  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_nulls(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d14125-eb7a-487e-9806-c37d821d12ea",
   "metadata": {},
   "source": [
    "From the output above, we can see that we have null values in 3 columns: 'sex', 'age' and `guardian`.\n",
    "\n",
    "Let us understand one thing we intend to do:\n",
    "\n",
    "1. **Numerical Null Values**: These are missing or undefined values in a dataset. In a dataset, such instances might be represented as `NaN` (Not a Number) or some other placeholder indicating that data is missing.\n",
    "\n",
    "2. **Setting Null Values to -999.0**: Before feeding data into a machine learning model, it's often necessary to handle these missing values. One approach is to replace them with a distinct numerical value that does not naturally occur in the dataset. In this case, `-999.0` is suggested as a replacement. The idea is to use a value that clearly stands out from valid data, ensuring that the model recognizes it as different from other, meaningful values.\n",
    "\n",
    "3. **XGBoost and the `missing` Hyperparameter**: XGBoost is a popular gradient boosting framework for machine learning. It has a feature to handle missing values efficiently. The `missing` hyperparameter in XGBoost allows you to specify the placeholder value you've used for missing data (in this case, `-999.0`). When XGBoost encounters this value during training, it treats it as a missing value.\n",
    "\n",
    "4. **How XGBoost Handles These Values**: XGBoost, during its training process, tries to find the best way to handle these specified missing values. It determines how to split nodes in its trees considering the missing values, effectively learning whether to group them with certain values or treat them separately. This is part of the model's training process to make the best possible decision at each stage of the boosting process.\n",
    "\n",
    "In summary, this technique of setting numerical null values to a distinct value like `-999.0` and informing XGBoost through the `missing` hyperparameter allows the model to treat missing values appropriately during training. This can be particularly useful when you cannot impute missing values with more conventional methods or when the presence of missing data itself might be informative for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad4137ac-08ad-499e-89a1-043723e5f877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>reason</th>\n",
       "      <th>guardian</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>schoolsup</th>\n",
       "      <th>famsup</th>\n",
       "      <th>paid</th>\n",
       "      <th>activities</th>\n",
       "      <th>nursery</th>\n",
       "      <th>higher</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>course</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  school  sex   age address famsize Pstatus  Medu  Fedu     Mjob     Fjob  \\\n",
       "0     GP  NaN  18.0       U     GT3       A     4     4  at_home  teacher   \n",
       "\n",
       "   reason guardian  traveltime  studytime  failures schoolsup famsup paid  \\\n",
       "0  course      NaN           2          2         0       yes     no   no   \n",
       "\n",
       "  activities nursery higher internet romantic  famrel  freetime  goout  Dalc  \\\n",
       "0         no     yes    yes       no       no       4         3      4     1   \n",
       "\n",
       "   Walc  health  absences  G1  G2  G3  \n",
       "0     1       3         4   0  11  11  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tweak_data(df):\n",
    "    return (df\n",
    "            .assign (age = lambda x:  x['age'].fillna(-999.0))\n",
    "           )\n",
    "\n",
    "df_stud = tweak_data(df)\n",
    "show_nulls(df_stud)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ef9037-adcd-4fad-9dbb-542738bc3d57",
   "metadata": {},
   "source": [
    "We have eradicated one; two more to go\n",
    "\n",
    "For categorical columns, we can fill missing values using the mode, which is the most frequently occurring value in a column. While using the mode can sometimes alter the column's original distribution, this is typically only a concern when there are a significant number of null values. In our case, with only two missing values, the impact on the distribution is negligible. An alternative approach is to substitute categorical null values with a label such as 'unknown'. This label can be transformed into a distinct column during one-hot encoding.\r\n",
    "\r\n",
    "The code below demonstrates how to replace missing values in the 'sex' and 'guardian' columns with their respective modes:\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01065448-6f42-4294-a4c1-7a04c474973e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>reason</th>\n",
       "      <th>guardian</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>schoolsup</th>\n",
       "      <th>famsup</th>\n",
       "      <th>paid</th>\n",
       "      <th>activities</th>\n",
       "      <th>nursery</th>\n",
       "      <th>higher</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [school, sex, age, address, famsize, Pstatus, Medu, Fedu, Mjob, Fjob, reason, guardian, traveltime, studytime, failures, schoolsup, famsup, paid, activities, nursery, higher, internet, romantic, famrel, freetime, goout, Dalc, Walc, health, absences, G1, G2, G3]\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tweak_data(df):\n",
    "    return (df\n",
    "            .assign (age = lambda x:  x['age'].fillna(-999.0),\n",
    "                    sex = lambda x: x['sex'].fillna(x['sex'].mode()),\n",
    "                    guardian = lambda x: x['guardian'].fillna(x['guardian'].mode()),)\n",
    "           )\n",
    "\n",
    "df_stud = tweak_data(df)\n",
    "show_nulls(df_stud)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55011ca4-d66d-41f6-b163-7e5c042c3a0e",
   "metadata": {},
   "source": [
    "From the output above, it seems like we have finally got rid of the null values like we intended.\n",
    "\n",
    "### One Hot Encoding\n",
    "\n",
    "#### Limitations of `pd.get_dummies`\n",
    "In previous work, we used `pd.get_dummies` from pandas to convert categorical variables into numerical form, where `0` represents absence and `1` represents presence. This method, while functional, has two key drawbacks:\n",
    "1. **Computational Load**: You might have noticed that `pd.get_dummies` can be quite slow, especially with large datasets.\n",
    "2. **Integration with Scikit-learn Pipelines**: The method doesnâ€™t integrate smoothly with scikit-learnâ€™s pipeline framework, which we will discuss shortly.\n",
    "\n",
    "#### The Advantage of Scikit-learnâ€™s `OneHotEncoder`\n",
    "As an alternative, scikit-learnâ€™s `OneHotEncoder` offers a more efficient solution:\n",
    "- **Efficient Representation**: It also converts categorical values into a 0/1 format but does so using a sparse matrix instead of a dense matrix. This results in significant space and time savings.\n",
    "- **Sparse Matrix Efficiency**: Sparse matrices are efficient because they store only non-zero elements, preserving the same information with less memory.\n",
    "- **Compatibility with Pipelines**: `OneHotEncoder` is a transformer in scikit-learn, designed to seamlessly fit into machine learning pipelines.\n",
    "\n",
    "#### Evolution of `OneHotEncoder`\n",
    "- **Historical Context**: In earlier versions of scikit-learn, `OneHotEncoder` required numerical inputs. To accommodate this, `LabelEncoder` was used as an intermediate step to numerically encode categorical data before one-hot encoding.\n",
    "- **Current Capability**: Now, `OneHotEncoder` can directly handle categorical inputs, streamlining the preprocessing step in machine learning pipelines.\n",
    "\n",
    "\n",
    "While while one-hot encoding isn't a strict requirement for XGBoost, its necessity and efficacy depend on the specific characteristics of your dataset and the problem you're tackling. It's usually recommended to test both approaches (with and without one-hot encoding) in the context of your specific dataset and problem. The impact of one-hot encoding can vary based on the nature of the data and the specific problem at hand.\n",
    "\n",
    "Let us select the categorical columns step by step. Stay with me on this please.\n",
    "\n",
    "First we check the columns with `Dtype` as object using the `.info` method of the pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e09324a-1967-4e2c-ba39-bd93bd634115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 649 entries, 0 to 648\n",
      "Data columns (total 33 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   school      649 non-null    object \n",
      " 1   sex         649 non-null    object \n",
      " 2   age         649 non-null    float64\n",
      " 3   address     649 non-null    object \n",
      " 4   famsize     649 non-null    object \n",
      " 5   Pstatus     649 non-null    object \n",
      " 6   Medu        649 non-null    int64  \n",
      " 7   Fedu        649 non-null    int64  \n",
      " 8   Mjob        649 non-null    object \n",
      " 9   Fjob        649 non-null    object \n",
      " 10  reason      649 non-null    object \n",
      " 11  guardian    649 non-null    object \n",
      " 12  traveltime  649 non-null    int64  \n",
      " 13  studytime   649 non-null    int64  \n",
      " 14  failures    649 non-null    int64  \n",
      " 15  schoolsup   649 non-null    object \n",
      " 16  famsup      649 non-null    object \n",
      " 17  paid        649 non-null    object \n",
      " 18  activities  649 non-null    object \n",
      " 19  nursery     649 non-null    object \n",
      " 20  higher      649 non-null    object \n",
      " 21  internet    649 non-null    object \n",
      " 22  romantic    649 non-null    object \n",
      " 23  famrel      649 non-null    int64  \n",
      " 24  freetime    649 non-null    int64  \n",
      " 25  goout       649 non-null    int64  \n",
      " 26  Dalc        649 non-null    int64  \n",
      " 27  Walc        649 non-null    int64  \n",
      " 28  health      649 non-null    int64  \n",
      " 29  absences    649 non-null    int64  \n",
      " 30  G1          649 non-null    int64  \n",
      " 31  G2          649 non-null    int64  \n",
      " 32  G3          649 non-null    int64  \n",
      "dtypes: float64(1), int64(15), object(17)\n",
      "memory usage: 167.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_stud.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb550a7-5436-4da4-83cc-44a076b13fee",
   "metadata": {},
   "source": [
    "We now create a boolean mask that selects those columns with `dtypes=object`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8abd15dc-2306-4c7b-b51d-d086555c9a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "school         True\n",
       "sex            True\n",
       "age           False\n",
       "address        True\n",
       "famsize        True\n",
       "Pstatus        True\n",
       "Medu          False\n",
       "Fedu          False\n",
       "Mjob           True\n",
       "Fjob           True\n",
       "reason         True\n",
       "guardian       True\n",
       "traveltime    False\n",
       "studytime     False\n",
       "failures      False\n",
       "schoolsup      True\n",
       "famsup         True\n",
       "paid           True\n",
       "activities     True\n",
       "nursery        True\n",
       "higher         True\n",
       "internet       True\n",
       "romantic       True\n",
       "famrel        False\n",
       "freetime      False\n",
       "goout         False\n",
       "Dalc          False\n",
       "Walc          False\n",
       "health        False\n",
       "absences      False\n",
       "G1            False\n",
       "G2            False\n",
       "G3            False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stud.dtypes==object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29c90bb-cbe8-457d-bfeb-c7f739cfd41a",
   "metadata": {},
   "source": [
    "We now subset it and select then names of the columns, convet to a list then save it to a variable name of our choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82c779bd-8aa6-44e0-8089-e2e799949c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob',\n",
       "       'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities',\n",
       "       'nursery', 'higher', 'internet', 'romantic'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stud.columns[df_stud.dtypes==object]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1595e815-ffd7-449e-9abc-2d59d6ba92dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['school',\n",
       " 'sex',\n",
       " 'address',\n",
       " 'famsize',\n",
       " 'Pstatus',\n",
       " 'Mjob',\n",
       " 'Fjob',\n",
       " 'reason',\n",
       " 'guardian',\n",
       " 'schoolsup',\n",
       " 'famsup',\n",
       " 'paid',\n",
       " 'activities',\n",
       " 'nursery',\n",
       " 'higher',\n",
       " 'internet',\n",
       " 'romantic']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols = df_stud.columns[df_stud.dtypes==object].tolist()\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5bb1ddeb-e1e9-419a-afd4-24cdf952710a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  initialize OneHotEncoder\n",
    "ohe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4abb576c-a043-4041-b8dd-839fd4368c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Use the fit_transform method on the columns\n",
    "hot = ohe.fit_transform(df_stud[cat_cols])\n",
    "\n",
    "print(type(hot))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "27324790-4240-499b-a266-2eb43350ccd6",
   "metadata": {},
   "source": [
    "# Optional: convert the one-hot encoded sparse matrix into a standard array and convert it into a DataFrame for viewing:\n",
    "hot_df = pd.DataFrame(hot.toarray())\n",
    "hot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "33b49fa8-f679-459b-82ff-38648e2e3b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_1</th>\n",
       "      <th>school_2</th>\n",
       "      <th>sex_1</th>\n",
       "      <th>sex_2</th>\n",
       "      <th>address_1</th>\n",
       "      <th>address_2</th>\n",
       "      <th>famsize_1</th>\n",
       "      <th>famsize_2</th>\n",
       "      <th>Pstatus_1</th>\n",
       "      <th>Pstatus_2</th>\n",
       "      <th>Mjob_1</th>\n",
       "      <th>Mjob_2</th>\n",
       "      <th>Mjob_3</th>\n",
       "      <th>Mjob_4</th>\n",
       "      <th>Mjob_5</th>\n",
       "      <th>Fjob_1</th>\n",
       "      <th>Fjob_2</th>\n",
       "      <th>Fjob_3</th>\n",
       "      <th>Fjob_4</th>\n",
       "      <th>Fjob_5</th>\n",
       "      <th>reason_1</th>\n",
       "      <th>reason_2</th>\n",
       "      <th>reason_3</th>\n",
       "      <th>reason_4</th>\n",
       "      <th>guardian_1</th>\n",
       "      <th>guardian_2</th>\n",
       "      <th>guardian_3</th>\n",
       "      <th>schoolsup_1</th>\n",
       "      <th>schoolsup_2</th>\n",
       "      <th>famsup_1</th>\n",
       "      <th>famsup_2</th>\n",
       "      <th>paid_1</th>\n",
       "      <th>paid_2</th>\n",
       "      <th>activities_1</th>\n",
       "      <th>activities_2</th>\n",
       "      <th>nursery_1</th>\n",
       "      <th>nursery_2</th>\n",
       "      <th>higher_1</th>\n",
       "      <th>higher_2</th>\n",
       "      <th>internet_1</th>\n",
       "      <th>internet_2</th>\n",
       "      <th>romantic_1</th>\n",
       "      <th>romantic_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     school_1  school_2  sex_1  sex_2  address_1  address_2  famsize_1  \\\n",
       "592         0         1      1      0          1          0          1   \n",
       "622         0         1      0      1          0          1          1   \n",
       "361         1         0      0      1          1          0          1   \n",
       "642         0         1      1      0          1          0          1   \n",
       "483         0         1      1      0          0          1          1   \n",
       "\n",
       "     famsize_2  Pstatus_1  Pstatus_2  Mjob_1  Mjob_2  Mjob_3  Mjob_4  Mjob_5  \\\n",
       "592          0          0          1       0       0       0       1       0   \n",
       "622          0          0          1       1       0       0       0       0   \n",
       "361          0          0          1       0       1       0       0       0   \n",
       "642          0          0          1       0       0       0       0       1   \n",
       "483          0          0          1       0       0       1       0       0   \n",
       "\n",
       "     Fjob_1  Fjob_2  Fjob_3  Fjob_4  Fjob_5  reason_1  reason_2  reason_3  \\\n",
       "592       0       0       1       0       0         1         0         0   \n",
       "622       0       1       0       0       0         1         0         0   \n",
       "361       0       1       0       0       0         1         0         0   \n",
       "642       0       1       0       0       0         0         1         0   \n",
       "483       0       1       0       0       0         1         0         0   \n",
       "\n",
       "     reason_4  guardian_1  guardian_2  guardian_3  schoolsup_1  schoolsup_2  \\\n",
       "592         0           1           0           0            0            1   \n",
       "622         0           1           0           0            0            1   \n",
       "361         0           1           0           0            0            1   \n",
       "642         0           1           0           0            0            1   \n",
       "483         0           0           1           0            0            1   \n",
       "\n",
       "     famsup_1  famsup_2  paid_1  paid_2  activities_1  activities_2  \\\n",
       "592         0         1       1       0             1             0   \n",
       "622         0         1       0       1             1             0   \n",
       "361         0         1       1       0             0             1   \n",
       "642         1         0       1       0             1             0   \n",
       "483         0         1       1       0             1             0   \n",
       "\n",
       "     nursery_1  nursery_2  higher_1  higher_2  internet_1  internet_2  \\\n",
       "592          1          0         1         0           0           1   \n",
       "622          1          0         1         0           1           0   \n",
       "361          1          0         1         0           0           1   \n",
       "642          1          0         1         0           0           1   \n",
       "483          1          0         0         1           0           1   \n",
       "\n",
       "     romantic_1  romantic_2  \n",
       "592           1           0  \n",
       "622           1           0  \n",
       "361           0           1  \n",
       "642           1           0  \n",
       "483           1           0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hot.sample(n=5, random_state=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3225f6e7-330b-4b1b-ab88-cb81425c1b13",
   "metadata": {},
   "source": [
    "Let's isolate the numerical columns. This may be done with the `exclude=[\"object\"]` parameter as input for `df.select_dtypes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0b384513-a121-4fc0-9978-8775493846c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>17.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>19.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>17.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  Medu  Fedu  traveltime  studytime  failures  famrel  freetime  \\\n",
       "592  17.0     3     3           2          1         0       4         4   \n",
       "622  18.0     1     3           2          2         0       3         3   \n",
       "361  19.0     4     2           2          2         0       5         4   \n",
       "642  17.0     4     3           2          2         0       5         5   \n",
       "483  16.0     2     2           3          2         0       3         4   \n",
       "\n",
       "     goout  Dalc  Walc  health  absences  G1  G2  G3  \n",
       "592      3     1     1       4         0  11  12  13  \n",
       "622      4     2     4       3         0   8  10   9  \n",
       "361      4     1     1       1         9  11  10  10  \n",
       "642      4     1     1       1         0   6   9  11  \n",
       "483      5     1     2       1         1   9  10  11  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cold_df = df_stud.select_dtypes(exclude=[\"object\"])\n",
    "\n",
    "cold_df.sample(n=5, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a70a0fc-d9fe-4626-af5b-42cfe71c1962",
   "metadata": {},
   "outputs": [],
   "source": [
    "cold = csr_matrix(cold_df)\n",
    "hot = csr_matrix(hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "589f8a23-0bd4-412e-8c98-38afefa98a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sparse_matrix = hstack((hot, cold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fba1cd09-89dc-40fa-a674-ba02bd70abd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8    9    10   11   12   13  \\\n",
       "592  0.0  1.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0   \n",
       "622  0.0  1.0  0.0  1.0  0.0  1.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0   \n",
       "361  1.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0   \n",
       "642  0.0  1.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "483  0.0  1.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0   \n",
       "\n",
       "      14   15   16   17   18   19   20   21   22   23   24   25   26   27  \\\n",
       "592  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "622  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "361  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "642  1.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "483  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "\n",
       "      28   29   30   31   32   33   34   35   36   37   38   39   40   41  \\\n",
       "592  1.0  0.0  1.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0  1.0   \n",
       "622  1.0  0.0  1.0  0.0  1.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0   \n",
       "361  1.0  0.0  1.0  1.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0   \n",
       "642  1.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0  1.0   \n",
       "483  1.0  0.0  1.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  1.0   \n",
       "\n",
       "      42    43   44   45   46   47   48   49   50   51   52   53   54   55  \\\n",
       "592  0.0  17.0  3.0  3.0  2.0  1.0  0.0  4.0  4.0  3.0  1.0  1.0  4.0  0.0   \n",
       "622  0.0  18.0  1.0  3.0  2.0  2.0  0.0  3.0  3.0  4.0  2.0  4.0  3.0  0.0   \n",
       "361  1.0  19.0  4.0  2.0  2.0  2.0  0.0  5.0  4.0  4.0  1.0  1.0  1.0  9.0   \n",
       "642  0.0  17.0  4.0  3.0  2.0  2.0  0.0  5.0  5.0  4.0  1.0  1.0  1.0  0.0   \n",
       "483  0.0  16.0  2.0  2.0  3.0  2.0  0.0  3.0  4.0  5.0  1.0  2.0  1.0  1.0   \n",
       "\n",
       "       56    57    58  \n",
       "592  11.0  12.0  13.0  \n",
       "622   8.0  10.0   9.0  \n",
       "361  11.0  10.0  10.0  \n",
       "642   6.0   9.0  11.0  \n",
       "483   9.0  10.0  11.0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.DataFrame(final_sparse_matrix.toarray())\n",
    "\n",
    "final_df.sample(n=5, random_state=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17235fc6-a5f9-4a4b-8e5f-310888d51509",
   "metadata": {},
   "source": [
    "### Customizing Scikit-learn Transformers for Streamlined Data Processing\n",
    "\n",
    "Scikit-learn's transformers are crucial for preparing data for machine learning. They provide methods like `fit`, which computes parameters for a model, and `transform`, which applies these parameters to data. Conveniently, `fit_transform` combines these steps, streamlining the process.\n",
    "\n",
    "In a typical workflow, multiple transformers, including machine learning models, can be seamlessly integrated into a single pipeline. This setup allows for efficient handling of incoming data, where it is fit and transformed in the pipeline to produce the required format.\n",
    "\n",
    "Scikit-learn offers a variety of built-in transformers like `StandardScaler` for standardization, `Normalizer` for normalization, and `SimpleImputer` for handling missing values. However, when dealing with datasets that feature a mix of categorical and numerical columns, these standard options might not always fit the bill. In such scenarios, crafting custom transformers is a smart move.\n",
    "\n",
    "#### Crafting Custom Transformers\n",
    "\n",
    "To build custom transformers tailored to your specific needs, inherit from Scikit-learn's `TransformerMixin`. This is the cornerstone for creating transformers that align perfectly with your data processing requirements, ensuring greater control and efficiency in your machine learning pipelines.\n",
    "\n",
    "Here is a general code outline to create a customized transformer in scikit-learn:\n",
    "\n",
    "```python\n",
    "class YourClass(TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "\n",
    "        # insert code to transform X\n",
    "\n",
    "        return X\n",
    "```\n",
    "\n",
    "As you can see, you don't have to initialize anything, and fit can always return self. Simply put, you may place all your code for transforming the data under the transform method.\r\n",
    "\r\n",
    "Now that you see how customization works generally, let's create a customized transformer to handle different kinds of null values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc74f36-9989-4beb-8b82-5d1b0fd65713",
   "metadata": {},
   "source": [
    "#### Creating a Custom Scikit-learn Transformer for Null Value Imputation\n",
    "\n",
    "To tailor your data processing needs, especially for handling null values in a mixed-type DataFrame, you can create a custom transformer in Scikit-learn. Here's a step-by-step guide:\n",
    "\n",
    "1. **Start by Importing `TransformerMixin`**:\n",
    "   - This is essential for creating a custom transformer.\n",
    "   ```python\n",
    "   from sklearn.base import TransformerMixin\n",
    "   ```\n",
    "\n",
    "2. **Define Your Custom Transformer Class**:\n",
    "   - Derive your class from `TransformerMixin`.\n",
    "   ```python\n",
    "   class NullValueImputer(TransformerMixin):\n",
    "   ```\n",
    "\n",
    "3. **Initialize the Class**:\n",
    "   - The `__init__` method sets up the class. It's standard to have it do nothing for simple transformers.\n",
    "   ```python\n",
    "   def __init__(self):\n",
    "       pass\n",
    "   ```\n",
    "\n",
    "4. **Implement the `fit` Method**:\n",
    "   - This method prepares the transformer. For this use case, it just returns `self`, as no fitting is required for null value imputation.\n",
    "   ```python\n",
    "   def fit(self, X, y=None):\n",
    "       return self\n",
    "   ```\n",
    "\n",
    "5. **Craft the `transform` Method**:\n",
    "   - This is where the data transformation logic resides. \n",
    "   - The method iterates through columns, filling null values differently based on the column's data type.\n",
    "   ```python\n",
    "   def transform(self, X, y=None):\n",
    "       for column in X.columns:\n",
    "           if X[column].dtype == object:  # Handling string (object) columns\n",
    "               X[column] = X[column].fillna(X[column].mode()[0])  # Using mode for categorical data\n",
    "           else:\n",
    "               X[column] = X[column].fillna(-999.0)  # Using -999.0 for numerical data\n",
    "       return X\n",
    "   ```\n",
    "\n",
    "In the `transform` method, we handle null values differently based on the column type. For categorical (string) columns, we use the mode, while for numerical columns, we fill with a placeholder value (-999.0).\n",
    "\n",
    "The `y=None` parameter in `fit` and `transform` is a convention in Scikit-learn, especially for compatibility with the pipeline mechanism. It allows these methods to handle scenarios where a target variable (`y`) might or might not be present, especially useful when incorporating machine learning models into pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bb37edcd-ee6c-413c-87b8-283aab8a9b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NullValueImputer(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        None\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        for column in X.columns.tolist():\n",
    "            if column in X.columns[X.dtypes==object].tolist():\n",
    "                X[column] = X[column].fillna(X[column].mode())\n",
    "            else:\n",
    "                X[column]=X[column].fillna(-999.0)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3b1e0daf-4f72-4c70-b9a3-b22283c3aa5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>reason</th>\n",
       "      <th>guardian</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>schoolsup</th>\n",
       "      <th>famsup</th>\n",
       "      <th>paid</th>\n",
       "      <th>activities</th>\n",
       "      <th>nursery</th>\n",
       "      <th>higher</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [school, sex, age, address, famsize, Pstatus, Medu, Fedu, Mjob, Fjob, reason, guardian, traveltime, studytime, failures, schoolsup, famsup, paid, activities, nursery, higher, internet, romantic, famrel, freetime, goout, Dalc, Walc, health, absences, G1, G2, G3]\n",
       "Index: []"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(file_path, sep=';')\n",
    "nvi = NullValueImputer().fit_transform(df)\n",
    "show_nulls(nvi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69518a26-98ba-43a5-8790-77fe1fe5430a",
   "metadata": {},
   "source": [
    "#### One-Hot Encoding for Mixed Data with Custom Transformer\n",
    "\n",
    "To handle a dataset with mixed data types, we can create a custom transformer for one-hot encoding the categorical columns and then combine them with numerical columns. Here's how to do it using Scikit-learn's `TransformerMixin`:\n",
    "\n",
    "1. **Define Your Custom Transformer Class**:\n",
    "   - Begin by extending `TransformerMixin`.\n",
    "   ```python\n",
    "   from sklearn.base import TransformerMixin\n",
    "   from sklearn.preprocessing import OneHotEncoder\n",
    "   from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "   class MixedDataEncoder(TransformerMixin):\n",
    "   ```\n",
    "\n",
    "2. **Initialize the Class**:\n",
    "   - The `__init__` method is standard, typically doing nothing in this context.\n",
    "   ```python\n",
    "   def __init__(self):\n",
    "       pass\n",
    "   ```\n",
    "\n",
    "3. **Implement the `fit` Method**:\n",
    "   - This method prepares the transformer and returns `self`. No action is needed for this step.\n",
    "   ```python\n",
    "   def fit(self, X, y=None):\n",
    "       return self\n",
    "   ```\n",
    "\n",
    "4. **Craft the `transform` Method**:\n",
    "   - This method will handle the transformation of mixed data types.\n",
    "   - Steps include identifying categorical columns, applying one-hot encoding, and combining the results with numerical columns.\n",
    "   ```python\n",
    "   def transform(self, X, y=None):\n",
    "       # a) Identify categorical columns\n",
    "       categorical_columns = X.columns[X.dtypes == object].tolist()\n",
    "\n",
    "       # b) Initialize OneHotEncoder\n",
    "       ohe = OneHotEncoder()\n",
    "\n",
    "       # c) Apply OneHotEncoder to categorical columns\n",
    "       hot = ohe.fit_transform(X[categorical_columns])\n",
    "\n",
    "       # d) Extract numerical columns, excluding strings\n",
    "       cold_df = X.select_dtypes(exclude=[\"object\"])\n",
    "\n",
    "       # e) Convert the numerical DataFrame to a sparse matrix\n",
    "       cold = csr_matrix(cold_df)\n",
    "\n",
    "       # f) Combine the one-hot encoded and numerical data\n",
    "       final_sparse_matrix = hstack([hot, cold])\n",
    "\n",
    "       # g) Convert to CSR format for compatibility with certain algorithms like XGBoost\n",
    "       final_csr_matrix = final_sparse_matrix.tocsr()\n",
    "\n",
    "       return final_csr_matrix\n",
    "   ```\n",
    "\n",
    "By using this custom transformer, `MixedDataEncoder`, you can efficiently process datasets with both categorical and numerical data, making them ready for machine learning models like XGBoost. The final output is a CSR matrix that is compatible with many algorithms and is optimized for performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b7723518-dc80-4e6a-b083-097b676898ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseMatrix(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        None\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        categorical_columns= X.columns[X.dtypes==object].tolist()\n",
    "        ohe = OneHotEncoder() \n",
    "        hot = ohe.fit_transform(X[categorical_columns])\n",
    "        cold_df = X.select_dtypes(exclude=[\"object\"])\n",
    "        cold = csr_matrix(cold_df)\n",
    "        final_sparse_matrix = hstack((hot, cold))\n",
    "        final_csr_matrix = final_sparse_matrix.tocsr()\n",
    "        return final_csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e253e050-7520-4f0e-aa7d-b696c483bd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1.0\n",
      "  (0, 2)\t1.0\n",
      "  (0, 4)\t1.0\n",
      "  (0, 6)\t1.0\n",
      "  (0, 8)\t1.0\n",
      "  (0, 10)\t1.0\n",
      "  (0, 15)\t1.0\n",
      "  (0, 20)\t1.0\n",
      "  (0, 24)\t1.0\n",
      "  (0, 27)\t1.0\n",
      "  (0, 29)\t1.0\n",
      "  (0, 31)\t1.0\n",
      "  (0, 33)\t1.0\n",
      "  (0, 35)\t1.0\n",
      "  (0, 37)\t1.0\n",
      "  (0, 39)\t1.0\n",
      "  (0, 41)\t1.0\n",
      "  (0, 43)\t18.0\n",
      "  (0, 44)\t4.0\n",
      "  (0, 45)\t4.0\n",
      "  (0, 46)\t2.0\n",
      "  (0, 47)\t2.0\n",
      "  (0, 49)\t4.0\n",
      "  (0, 50)\t3.0\n",
      "  (0, 51)\t4.0\n",
      "  :\t:\n",
      "  (648, 20)\t1.0\n",
      "  (648, 24)\t1.0\n",
      "  (648, 28)\t1.0\n",
      "  (648, 29)\t1.0\n",
      "  (648, 31)\t1.0\n",
      "  (648, 33)\t1.0\n",
      "  (648, 36)\t1.0\n",
      "  (648, 37)\t1.0\n",
      "  (648, 40)\t1.0\n",
      "  (648, 41)\t1.0\n",
      "  (648, 43)\t18.0\n",
      "  (648, 44)\t3.0\n",
      "  (648, 45)\t2.0\n",
      "  (648, 46)\t3.0\n",
      "  (648, 47)\t1.0\n",
      "  (648, 49)\t4.0\n",
      "  (648, 50)\t4.0\n",
      "  (648, 51)\t1.0\n",
      "  (648, 52)\t3.0\n",
      "  (648, 53)\t4.0\n",
      "  (648, 54)\t5.0\n",
      "  (648, 55)\t4.0\n",
      "  (648, 56)\t10.0\n",
      "  (648, 57)\t11.0\n",
      "  (648, 58)\t11.0\n"
     ]
    }
   ],
   "source": [
    "sm = SparseMatrix().fit_transform(nvi)\n",
    "print(sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dd026e43-8012-4134-97ce-88f19970344c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9    10   11   12   13   14  \\\n",
       "0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "1  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0   \n",
       "2  1.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0   \n",
       "3  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0   \n",
       "4  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0   \n",
       "\n",
       "    15   16   17   18   19   20   21   22   23   24   25   26   27   28   29  \\\n",
       "0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0   \n",
       "1  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0   \n",
       "2  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0   \n",
       "3  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0   \n",
       "4  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0   \n",
       "\n",
       "    30   31   32   33   34   35   36   37   38   39   40   41   42     43  \\\n",
       "0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0   18.0   \n",
       "1  1.0  1.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0  1.0  1.0  0.0 -999.0   \n",
       "2  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0   15.0   \n",
       "3  1.0  1.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0   15.0   \n",
       "4  1.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0   16.0   \n",
       "\n",
       "    44   45   46   47   48   49   50   51   52   53   54   55    56    57  \\\n",
       "0  4.0  4.0  2.0  2.0  0.0  4.0  3.0  4.0  1.0  1.0  3.0  4.0   0.0  11.0   \n",
       "1  1.0  1.0  1.0  2.0  0.0  5.0  3.0  3.0  1.0  1.0  3.0  2.0   9.0  11.0   \n",
       "2  1.0  1.0  1.0  2.0  0.0  4.0  3.0  2.0  2.0  3.0  3.0  6.0  12.0  13.0   \n",
       "3  4.0  2.0  1.0  3.0  0.0  3.0  2.0  2.0  1.0  1.0  5.0  0.0  14.0  14.0   \n",
       "4  3.0  3.0  1.0  2.0  0.0  4.0  3.0  2.0  1.0  2.0  5.0  0.0  11.0  13.0   \n",
       "\n",
       "     58  \n",
       "0  11.0  \n",
       "1  11.0  \n",
       "2  12.0  \n",
       "3  14.0  \n",
       "4  13.0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_df = pd.DataFrame(sm.toarray())\n",
    "sm_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a5c0c6-1217-4c42-9607-4493d5302365",
   "metadata": {},
   "source": [
    "### Preprocessing pipeline\n",
    "\n",
    "When developing machine learning models, a critical step is to preprocess your data effectively. This usually involves setting up a pipeline for transforming your features (predictors) while leaving the target variable intact. Additionally, to evaluate your model effectively, it's essential to split your dataset into training and testing sets. \r\n",
    "\r\n",
    "Begin by dividing your dataset into features (X) and the target (y). This separation is crucial as it allows you to process and transform your features without affecting the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cff985bc-3c0e-4a28-9cac-26c5b20bada1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5331dbc-f682-43d8-8e7b-5fe295949f1e",
   "metadata": {},
   "source": [
    "When choosing X and y for the Student Performance dataset, it's important to note that the last three columns all include student grades. Two potential studies are of value here:\n",
    "\n",
    "a) Including previous grades as predictor columns\n",
    "\n",
    "b) Not including previous grades as predictor columns\n",
    "\n",
    "Assume that your EdTech company wants to make predictions based on socioeconomic variables, not on previous grades earned, so ignore the first two grade columns indexed as -2 and -3.\n",
    "\n",
    "Select the last column as y, and all columns except for the last three as X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1449bb7f-0373-4b9f-bd0c-60fe026e3e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.iloc[:, -1]\n",
    "\n",
    "X = df.iloc[:, :-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7098008a-77b7-4ccf-ab41-fe69b453d292",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fd01ac82-3e59-4ebc-9c7a-b3a1314b7084",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pipeline = Pipeline([('null_imputer', NullValueImputer()), \n",
    "                          ('sparse', SparseMatrix())]\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cff18bce-14f4-43a5-b919-c13001e9f370",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = data_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29642246-cb82-4020-81ba-3fb3b63c59b6",
   "metadata": {},
   "source": [
    "### Finalizing an XGBoost model\n",
    "It's time to build a robust XGBoost model to add to the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c50a1f64-34f2-41be-bfdf-64a3432e91c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "G3\n",
       "11    78\n",
       "10    68\n",
       "13    63\n",
       "12    51\n",
       "14    51\n",
       "15    36\n",
       "8     31\n",
       "16    29\n",
       "9     25\n",
       "17    20\n",
       "18    12\n",
       "0     11\n",
       "7      6\n",
       "6      2\n",
       "19     2\n",
       "5      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e826cb83-905c-4c30-8606-162026a18e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8d85d4bd-3d1b-4308-8b28-5dee03067918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(model):\n",
    "\n",
    "    scores = cross_val_score(model, X_train_transformed, y_train, scoring='neg_root_mean_squared_error', cv=kfold)\n",
    "\n",
    "    rmse = (-scores.mean())\n",
    "\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e413dd71-efb5-4af0-a617-0a383a42c67b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8759082084755994"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val(XGBRegressor(missing=-999.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f24c411b-bedd-42b2-bbac-3ee6fd8ba533",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_train_transformed, y_train, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cc2d7f82-cd6a-42ac-97f3-e68135bb3c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_estimators(model):\n",
    "    eval_set = [(X_test_2, y_test_2)]\n",
    "    eval_metric=\"rmse\"\n",
    "    model.fit(X_train_2, y_train_2, eval_metric=eval_metric, eval_set=eval_set, early_stopping_rounds=100)\n",
    "    y_pred = model.predict(X_test_2)\n",
    "    rmse = MSE(y_test_2, y_pred)**0.5\n",
    "    return rmse  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "efdab157-9901-47b1-8ae5-d4c113b9efd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:8.25434\n",
      "[1]\tvalidation_0-rmse:6.04610\n",
      "[2]\tvalidation_0-rmse:4.63637\n",
      "[3]\tvalidation_0-rmse:3.76622\n",
      "[4]\tvalidation_0-rmse:3.31774\n",
      "[5]\tvalidation_0-rmse:3.12871\n",
      "[6]\tvalidation_0-rmse:3.08479\n",
      "[7]\tvalidation_0-rmse:3.00243\n",
      "[8]\tvalidation_0-rmse:2.96403\n",
      "[9]\tvalidation_0-rmse:2.93577\n",
      "[10]\tvalidation_0-rmse:2.87623\n",
      "[11]\tvalidation_0-rmse:2.87114\n",
      "[12]\tvalidation_0-rmse:2.85060\n",
      "[13]\tvalidation_0-rmse:2.85854\n",
      "[14]\tvalidation_0-rmse:2.86017\n",
      "[15]\tvalidation_0-rmse:2.87909\n",
      "[16]\tvalidation_0-rmse:2.89732\n",
      "[17]\tvalidation_0-rmse:2.89801\n",
      "[18]\tvalidation_0-rmse:2.88963\n",
      "[19]\tvalidation_0-rmse:2.89084\n",
      "[20]\tvalidation_0-rmse:2.89787\n",
      "[21]\tvalidation_0-rmse:2.89785\n",
      "[22]\tvalidation_0-rmse:2.90117\n",
      "[23]\tvalidation_0-rmse:2.89989\n",
      "[24]\tvalidation_0-rmse:2.90361\n",
      "[25]\tvalidation_0-rmse:2.91006\n",
      "[26]\tvalidation_0-rmse:2.90656\n",
      "[27]\tvalidation_0-rmse:2.90807\n",
      "[28]\tvalidation_0-rmse:2.91110\n",
      "[29]\tvalidation_0-rmse:2.90573\n",
      "[30]\tvalidation_0-rmse:2.91392\n",
      "[31]\tvalidation_0-rmse:2.91448\n",
      "[32]\tvalidation_0-rmse:2.91121\n",
      "[33]\tvalidation_0-rmse:2.91648\n",
      "[34]\tvalidation_0-rmse:2.91652\n",
      "[35]\tvalidation_0-rmse:2.92127\n",
      "[36]\tvalidation_0-rmse:2.92190\n",
      "[37]\tvalidation_0-rmse:2.92694\n",
      "[38]\tvalidation_0-rmse:2.92949\n",
      "[39]\tvalidation_0-rmse:2.92816\n",
      "[40]\tvalidation_0-rmse:2.93079\n",
      "[41]\tvalidation_0-rmse:2.93136\n",
      "[42]\tvalidation_0-rmse:2.93622\n",
      "[43]\tvalidation_0-rmse:2.93471\n",
      "[44]\tvalidation_0-rmse:2.93721\n",
      "[45]\tvalidation_0-rmse:2.93708\n",
      "[46]\tvalidation_0-rmse:2.93604\n",
      "[47]\tvalidation_0-rmse:2.93548\n",
      "[48]\tvalidation_0-rmse:2.93586\n",
      "[49]\tvalidation_0-rmse:2.93977\n",
      "[50]\tvalidation_0-rmse:2.93926\n",
      "[51]\tvalidation_0-rmse:2.93970\n",
      "[52]\tvalidation_0-rmse:2.93940\n",
      "[53]\tvalidation_0-rmse:2.93982\n",
      "[54]\tvalidation_0-rmse:2.93892\n",
      "[55]\tvalidation_0-rmse:2.93693\n",
      "[56]\tvalidation_0-rmse:2.93681\n",
      "[57]\tvalidation_0-rmse:2.93781\n",
      "[58]\tvalidation_0-rmse:2.93636\n",
      "[59]\tvalidation_0-rmse:2.93639\n",
      "[60]\tvalidation_0-rmse:2.93648\n",
      "[61]\tvalidation_0-rmse:2.93566\n",
      "[62]\tvalidation_0-rmse:2.93594\n",
      "[63]\tvalidation_0-rmse:2.93531\n",
      "[64]\tvalidation_0-rmse:2.93521\n",
      "[65]\tvalidation_0-rmse:2.93407\n",
      "[66]\tvalidation_0-rmse:2.93418\n",
      "[67]\tvalidation_0-rmse:2.93406\n",
      "[68]\tvalidation_0-rmse:2.93407\n",
      "[69]\tvalidation_0-rmse:2.93414\n",
      "[70]\tvalidation_0-rmse:2.93423\n",
      "[71]\tvalidation_0-rmse:2.93444\n",
      "[72]\tvalidation_0-rmse:2.93443\n",
      "[73]\tvalidation_0-rmse:2.93430\n",
      "[74]\tvalidation_0-rmse:2.93429\n",
      "[75]\tvalidation_0-rmse:2.93398\n",
      "[76]\tvalidation_0-rmse:2.93411\n",
      "[77]\tvalidation_0-rmse:2.93410\n",
      "[78]\tvalidation_0-rmse:2.93420\n",
      "[79]\tvalidation_0-rmse:2.93425\n",
      "[80]\tvalidation_0-rmse:2.93433\n",
      "[81]\tvalidation_0-rmse:2.93404\n",
      "[82]\tvalidation_0-rmse:2.93422\n",
      "[83]\tvalidation_0-rmse:2.93424\n",
      "[84]\tvalidation_0-rmse:2.93425\n",
      "[85]\tvalidation_0-rmse:2.93422\n",
      "[86]\tvalidation_0-rmse:2.93407\n",
      "[87]\tvalidation_0-rmse:2.93387\n",
      "[88]\tvalidation_0-rmse:2.93399\n",
      "[89]\tvalidation_0-rmse:2.93447\n",
      "[90]\tvalidation_0-rmse:2.93461\n",
      "[91]\tvalidation_0-rmse:2.93457\n",
      "[92]\tvalidation_0-rmse:2.93453\n",
      "[93]\tvalidation_0-rmse:2.93441\n",
      "[94]\tvalidation_0-rmse:2.93437\n",
      "[95]\tvalidation_0-rmse:2.93436\n",
      "[96]\tvalidation_0-rmse:2.93440\n",
      "[97]\tvalidation_0-rmse:2.93436\n",
      "[98]\tvalidation_0-rmse:2.93438\n",
      "[99]\tvalidation_0-rmse:2.93447\n",
      "[100]\tvalidation_0-rmse:2.93454\n",
      "[101]\tvalidation_0-rmse:2.93456\n",
      "[102]\tvalidation_0-rmse:2.93457\n",
      "[103]\tvalidation_0-rmse:2.93453\n",
      "[104]\tvalidation_0-rmse:2.93454\n",
      "[105]\tvalidation_0-rmse:2.93451\n",
      "[106]\tvalidation_0-rmse:2.93451\n",
      "[107]\tvalidation_0-rmse:2.93447\n",
      "[108]\tvalidation_0-rmse:2.93448\n",
      "[109]\tvalidation_0-rmse:2.93446\n",
      "[110]\tvalidation_0-rmse:2.93445\n",
      "[111]\tvalidation_0-rmse:2.93447\n",
      "[112]\tvalidation_0-rmse:2.93447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.8506019849126356"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators(XGBRegressor(n_estimators=5000, missing=-999.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b79c1d56-48b7-4148-8585-033359fbc1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(params, reg=XGBRegressor(missing=-999.0)):\n",
    "    grid_reg = GridSearchCV(reg, params, scoring='neg_mean_squared_error', cv=kfold)\n",
    "    grid_reg.fit(X_train_transformed, y_train)\n",
    "    best_params = grid_reg.best_params_\n",
    "    print(f\"Best params:{best_params}\")\n",
    "    best_score = np.sqrt(-grid_reg.best_score_)\n",
    "    print(f\"Best score: {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e53946ee-6138-4534-bbc0-dabf5de1b4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:{'max_depth': 1, 'n_estimators': 31}\n",
      "Best score: 2.6995781876875076\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'max_depth':[1, 2, 3, 4, 6, 7, 8], \n",
    "                    'n_estimators':[31]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b993de9d-c40c-47fd-8c0e-1dbcabee297f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:{'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 31}\n",
      "Best score: 2.685269482586703\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'max_depth':[1, 2], \n",
    "                    'min_child_weight':[1,2,3,4,5], \n",
    "                    'n_estimators':[31]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f0a318bf-905e-4f35-bb5d-c09c719d0d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:{'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 50, 'subsample': 0.8}\n",
      "Best score: 2.678420215321727\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'max_depth':[2],\n",
    "                    'min_child_weight':[2,3, 4],\n",
    "                    'subsample':[0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "                   'n_estimators':[31, 50]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "62989a2d-5ea4-4934-973d-9326156b8977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:{'colsample_bytree': 0.7, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 50, 'subsample': 0.9}\n",
      "Best score: 2.6615511570768837\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'max_depth':[2],\n",
    "                    'min_child_weight':[3,4,5], \n",
    "                    'subsample':[0.8, 0.9, 1], \n",
    "                    'colsample_bytree':[0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "                   'n_estimators':[50]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c0c5b051-7ebf-4aa5-b4d2-b409a0ff58a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:{'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 0.7, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 50, 'subsample': 0.9}\n",
      "Best score: 2.6615511570768837\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'max_depth':[2],\n",
    "                    'min_child_weight':[3], \n",
    "                    'subsample':[.9], \n",
    "                    'colsample_bytree':[0.7],\n",
    "                    'colsample_bylevel':[0.6, 0.7, 0.8, 0.9, 1],\n",
    "                    'colsample_bynode':[0.6, 0.7, 0.8, 0.9, 1],\n",
    "                    'n_estimators':[50]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "be81d3b5-0bbe-4d59-8e6a-06bbacf205c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6547125392710713"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val(XGBRegressor(max_depth=2,\n",
    "                       min_child_weight=3,\n",
    "                       subsample=0.9, \n",
    "                       colsample_bytree=0.7, \n",
    "                       colsample_bylevel=1.0,\n",
    "                       colsample_bynode=1.0, \n",
    "                       missing=-999.0,\n",
    "                       booster='dart',\n",
    "                      one_drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bb470460-a15a-47e5-9e96-3ff875375835",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed = data_pipeline.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "333a56cc-7f37-45aa-95bd-0d6560706f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b041c68c-3ab9-4caf-9156-2f277202cdfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.145871582757146"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBRegressor(max_depth=2,\n",
    "                       min_child_weight=3,\n",
    "                       subsample=0.9, \n",
    "                       colsample_bytree=0.7, \n",
    "                       colsample_bylevel=1.0,\n",
    "                       colsample_bynode=1.0,\n",
    "                     n_estimators=50,\n",
    "                       missing=-999.0)\n",
    "model.fit(X_train_transformed, y_train)\n",
    "y_pred = model.predict(X_test_transformed)\n",
    "rmse = MSE(y_pred, y_test)**0.5\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9e0bf934-ad5b-4094-b736-b4f10575e795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2177922264217833"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBRegressor(max_depth=2,\n",
    "                       min_child_weight=5,\n",
    "                       subsample=0.6, \n",
    "                       colsample_bytree=0.9, \n",
    "                       colsample_bylevel=0.9,\n",
    "                       colsample_bynode=0.8,\n",
    "                     n_estimators=50,\n",
    "                       missing=-999.0)\n",
    "model.fit(X_train_transformed, y_train)\n",
    "y_pred = model.predict(X_test_transformed)\n",
    "rmse = MSE(y_pred, y_test)**0.5\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced0bceb-7dd5-4142-a9e9-05cc6dfc84b5",
   "metadata": {},
   "source": [
    "#### Building a machine learning pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "122c5a43-878f-4dbb-8082-9bb64cf213a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = Pipeline([('null_imputer', NullValueImputer()), \n",
    "                          ('sparse', SparseMatrix()), \n",
    "                          ('xgb', XGBRegressor(max_depth=2,\n",
    "                                               min_child_weight=3,\n",
    "                                               subsample=0.9, \n",
    "                                               colsample_bytree=0.9, \n",
    "                                               colsample_bylevel=0.9,\n",
    "                                               colsample_bynode=0.8, \n",
    "                                               missing=-999.0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "959ca292-fec3-469b-848a-2e38c1d3d965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;null_imputer&#x27;,\n",
       "                 &lt;__main__.NullValueImputer object at 0x7fa7246d1240&gt;),\n",
       "                (&#x27;sparse&#x27;, &lt;__main__.SparseMatrix object at 0x7fa7246d2f20&gt;),\n",
       "                (&#x27;xgb&#x27;,\n",
       "                 XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                              colsample_bylevel=0.9, colsample_bynode=0.8,\n",
       "                              colsample_bytree=0.9, early_stopping_rounds=None,\n",
       "                              enable_categorical=False, eval_metric=None,\n",
       "                              feature_types...None,\n",
       "                              grow_policy=None, importance_type=None,\n",
       "                              interaction_constraints=None, learning_rate=None,\n",
       "                              max_bin=None, max_cat_threshold=None,\n",
       "                              max_cat_to_onehot=None, max_delta_step=None,\n",
       "                              max_depth=2, max_leaves=None, min_child_weight=3,\n",
       "                              missing=-999.0, monotone_constraints=None,\n",
       "                              n_estimators=100, n_jobs=None,\n",
       "                              num_parallel_tree=None, predictor=None,\n",
       "                              random_state=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;null_imputer&#x27;,\n",
       "                 &lt;__main__.NullValueImputer object at 0x7fa7246d1240&gt;),\n",
       "                (&#x27;sparse&#x27;, &lt;__main__.SparseMatrix object at 0x7fa7246d2f20&gt;),\n",
       "                (&#x27;xgb&#x27;,\n",
       "                 XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                              colsample_bylevel=0.9, colsample_bynode=0.8,\n",
       "                              colsample_bytree=0.9, early_stopping_rounds=None,\n",
       "                              enable_categorical=False, eval_metric=None,\n",
       "                              feature_types...None,\n",
       "                              grow_policy=None, importance_type=None,\n",
       "                              interaction_constraints=None, learning_rate=None,\n",
       "                              max_bin=None, max_cat_threshold=None,\n",
       "                              max_cat_to_onehot=None, max_delta_step=None,\n",
       "                              max_depth=2, max_leaves=None, min_child_weight=3,\n",
       "                              missing=-999.0, monotone_constraints=None,\n",
       "                              n_estimators=100, n_jobs=None,\n",
       "                              num_parallel_tree=None, predictor=None,\n",
       "                              random_state=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NullValueImputer</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.NullValueImputer object at 0x7fa7246d1240&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SparseMatrix</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.SparseMatrix object at 0x7fa7246d2f20&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=0.9, colsample_bynode=0.8, colsample_bytree=0.9,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, gamma=None, gpu_id=None,\n",
       "             grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=2, max_leaves=None,\n",
       "             min_child_weight=3, missing=-999.0, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('null_imputer',\n",
       "                 <__main__.NullValueImputer object at 0x7fa7246d1240>),\n",
       "                ('sparse', <__main__.SparseMatrix object at 0x7fa7246d2f20>),\n",
       "                ('xgb',\n",
       "                 XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                              colsample_bylevel=0.9, colsample_bynode=0.8,\n",
       "                              colsample_bytree=0.9, early_stopping_rounds=None,\n",
       "                              enable_categorical=False, eval_metric=None,\n",
       "                              feature_types...None,\n",
       "                              grow_policy=None, importance_type=None,\n",
       "                              interaction_constraints=None, learning_rate=None,\n",
       "                              max_bin=None, max_cat_threshold=None,\n",
       "                              max_cat_to_onehot=None, max_delta_step=None,\n",
       "                              max_depth=2, max_leaves=None, min_child_weight=3,\n",
       "                              missing=-999.0, monotone_constraints=None,\n",
       "                              n_estimators=100, n_jobs=None,\n",
       "                              num_parallel_tree=None, predictor=None,\n",
       "                              random_state=None, ...))])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "acc6dece-1320-4910-8577-de20f75d70cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.438138 , 10.877554 , 10.332089 , 13.583207 ,  8.323381 ,\n",
       "        8.641584 , 11.806151 ,  8.323174 , 10.84991  ,  9.507316 ,\n",
       "       13.3785095, 10.609498 , 11.464302 , 13.332452 ,  6.5241427,\n",
       "       12.291414 ,  8.485447 , 12.476763 ,  9.387565 , 11.207339 ,\n",
       "        9.424469 , 11.871625 ,  7.666484 , 12.4861355,  8.729989 ,\n",
       "        9.376352 ,  9.383465 , 11.994037 ,  8.125768 , 12.351852 ,\n",
       "       11.570734 , 11.633892 , 11.641348 , 14.577013 , 11.7222595,\n",
       "       13.286118 , 13.434792 ,  8.953255 , 11.459575 , 10.527292 ,\n",
       "       11.271511 , 12.72165  , 10.577722 ,  6.1928163, 12.027768 ,\n",
       "       11.150083 , 11.3822   ,  8.45433  , 10.173357 , 10.533948 ,\n",
       "        8.505165 ,  9.017391 ,  7.7787123, 12.646953 , 10.67798  ,\n",
       "       12.386895 ,  9.727485 ,  7.3675466, 10.130199 ,  9.060929 ,\n",
       "       10.857667 ,  9.084782 , 11.2500515, 11.436306 , 10.409196 ,\n",
       "        7.722747 ,  8.883924 ,  9.706495 , 10.367291 , 11.169585 ,\n",
       "        9.953716 , 10.706625 ,  8.798611 ,  9.947971 , 10.196384 ,\n",
       "       13.201183 , 10.791653 , 13.00497  , 10.121918 ,  9.207968 ,\n",
       "       11.3626995, 12.683471 ,  9.382515 , 13.064207 , 11.703074 ,\n",
       "        6.863064 , 14.436304 , 11.375392 , 11.275094 ,  9.222486 ,\n",
       "        8.061456 , 12.990812 , 12.608954 ,  9.837554 ,  9.411427 ,\n",
       "       11.725041 , 11.548682 ,  5.8692894,  8.245462 , 12.151258 ,\n",
       "       13.399112 , 10.8647995, 10.506218 ,  8.419824 ,  6.4527693,\n",
       "       12.792156 , 10.698982 , 11.078963 , 11.177805 ,  9.784167 ,\n",
       "       12.676808 , 12.9967   ,  9.827728 , 10.514228 , 10.973807 ,\n",
       "       10.67493  , 10.2993145, 14.120635 , 11.718488 , 11.80545  ,\n",
       "       10.827226 , 12.102346 , 11.368238 ,  8.743835 ,  9.7585   ,\n",
       "        8.243097 ,  9.136635 , 12.076728 ,  7.0144653,  9.5018425,\n",
       "       11.16409  , 11.192847 , 13.300002 , 12.522902 , 12.254616 ,\n",
       "       12.344936 , 10.523251 , 12.227174 , 11.042469 ,  7.6465745,\n",
       "       10.242628 , 11.241503 , 13.615909 ,  9.945598 , 11.542598 ,\n",
       "        9.843366 , 11.323808 ,  8.448171 ,  7.771019 , 10.970168 ,\n",
       "       11.645315 ,  6.72241  ,  7.005892 ,  9.428023 , 11.150103 ,\n",
       "       10.14605  , 11.134749 , 12.76121  ,  9.423827 , 12.877959 ,\n",
       "       11.474351 , 10.341606 , 10.1600895], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = X_test\n",
    "full_pipeline.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3bf822a3-9e74-4f51-a5f5-c80950ddda99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13., 11., 10., 14.,  8.,  9., 12.,  8., 11., 10., 13., 11., 11.,\n",
       "       13.,  7., 12.,  8., 12.,  9., 11.,  9., 12.,  8., 12.,  9.,  9.,\n",
       "        9., 12.,  8., 12., 12., 12., 12., 15., 12., 13., 13.,  9., 11.,\n",
       "       11., 11., 13., 11.,  6., 12., 11., 11.,  8., 10., 11.,  9.,  9.,\n",
       "        8., 13., 11., 12., 10.,  7., 10.,  9., 11.,  9., 11., 11., 10.,\n",
       "        8.,  9., 10., 10., 11., 10., 11.,  9., 10., 10., 13., 11., 13.,\n",
       "       10.,  9., 11., 13.,  9., 13., 12.,  7., 14., 11., 11.,  9.,  8.,\n",
       "       13., 13., 10.,  9., 12., 12.,  6.,  8., 12., 13., 11., 11.,  8.,\n",
       "        6., 13., 11., 11., 11., 10., 13., 13., 10., 11., 11., 11., 10.,\n",
       "       14., 12., 12., 11., 12., 11.,  9., 10.,  8.,  9., 12.,  7., 10.,\n",
       "       11., 11., 13., 13., 12., 12., 11., 12., 11.,  8., 10., 11., 14.,\n",
       "       10., 12., 10., 11.,  8.,  8., 11., 12.,  7.,  7.,  9., 11., 10.,\n",
       "       11., 13.,  9., 13., 11., 10., 10.], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(full_pipeline.predict(new_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a4142ac2-cede-428d-946d-cab8908efb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df = pd.read_csv(file_path, sep=';')\n",
    "new_X = df.iloc[:, :-3]\n",
    "new_y = df.iloc[:, -1]\n",
    "new_model = full_pipeline.fit(new_X, new_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf227147-9377-4f14-af89-ea60253b38aa",
   "metadata": {},
   "source": [
    "Now, this model may be used to make predictions on new data, as shown in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "82836eee-d95e-4dbf-8bc0-d536e92fd568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13., 11., 10., 14.,  8.,  9., 12.,  8., 11., 10., 13., 11., 11.,\n",
       "       13.,  7., 12.,  8., 12.,  9., 11.,  9., 12.,  8., 12.,  9.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "more_new_data = X_test[:25]\n",
    "np.round(new_model.predict(more_new_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22058d2-104a-49b1-9c7a-88083901a9fa",
   "metadata": {},
   "source": [
    "When attempting to predict using only one row of data, a challenge arises if you use a pipeline that includes one-hot encoding. The issue is that the sparse matrix created by encoding just one row will lack the necessary number of columns. This happens because the encoding only includes categories present in that single row. Consequently, this leads to a dimension mismatch error, as the machine learning model expects a sparse matrix with a broader range of data.\n",
    "\n",
    "To overcome this, a practical approach is to merge the new row with a sufficient number of existing data rows. This ensures that all potential categorical columns are represented in the transformed sparse matrix. In a specific example, appending the single row with the first 25 rows from `X_test` has been proven effective, as it avoids errors. However, using only 20 or fewer rows from `X_test` may still lead to a mismatch error in this context.\n",
    "\n",
    "Therefore, for accurate prediction with a single row of data, combine this row with the initial 25 rows of `X_test`. Here's how you can proceed with the prediction:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ce709ad6-e63c-408a-adfa-32691ded920d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.]\n"
     ]
    }
   ],
   "source": [
    "single_row = X_test[:1]\n",
    "single_row_plus = pd.concat([single_row, X_test[:25]])\n",
    "print(np.round(new_model.predict(single_row_plus))[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4caf8b-d6df-4e88-a965-23b0c4caaaaa",
   "metadata": {},
   "source": [
    "Kudos on completing this walk through with me. Our learning odyssey began with fundamental machine learning concepts and pandas and culminated in mastering the art of crafting bespoke transformers, pipelines, and functions. These skills enable us to deploy sophisticated, finely-tuned XGBoost models in real-world industry scenarios, adept at handling sparse matrices for new data predictions.\n",
    "\n",
    "Our journey encompassed an in-depth exploration of XGBoost's evolution: starting from basic decision trees, advancing through random forests and gradient boosting, to unraveling the complex mathematics that underpins XGBoost's effectiveness. We've observed XGBoost's superior performance compared to other algorithms and honed our skills in optimizing its extensive hyperparameters, like `n_estimators`, `max_depth`, `gamma`, `colsample_bylevel`, `missing`, and `scale_pos_weight`.\n",
    "\n",
    "We have gone through pivotal historical case studies in physics and astronomy, enhancing our understanding of XGBoost's versatility, especially in handling imbalanced datasets and employing alternative base learners. Insights from Kaggle competitions provided us with advanced techniques in feature engineering, creating non-correlated ensembles, and stacking. Additionally, we delved into advanced automation techniques for industrial applications.\n",
    "\n",
    "Now, with advanced knowledge of XGBoost, we're equipped to efficiently and effectively address diverse machine learning challenges. While XGBoost excels in numerous areas, particularly with structured data, it's important to remember its limitations with unstructured data, where neural networks might be more suitable.\n",
    "\n",
    "For those of us eager to delve deeper into XGBoost, participating in Kaggle competitions is highly recommended. Competing against seasoned practitioners will sharpen our skills, and the collaborative environment of Kaggle, with shared notebooks and discussions, will enrich our learning experience. This platform is where XGBoost solidified its impressive reputation, particularly in the Higgs boson competition highlighted in this walk-through.\n",
    "\n",
    "With this knowledge, we're well-prepared to venture into the realm of big data, leveraging XGBoost to push the boundaries of research, excel in competitions, and develop robust, production-ready machine learning models.\n",
    "\n",
    "Thank you for hanging in there with me.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9719b8c5-fb13-4566-a931-1ec362171d34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
