{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e85032fe-f7ee-4649-9795-05bc5f7543f1",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;\">Higgs Boson: A Case Study</h1>\n",
    "\n",
    "# Introduction\n",
    "\n",
    "Ah, the journey to finding the Higgs boson! Let's delve into this ntoebook where the renowned Higgs Boson Kaggle Competition, and XGBoost, our machine learning hero, share the stage.\n",
    "\n",
    "## A Glimpse into the Past: Physics and the Higgs Boson\n",
    "\n",
    "Known colloquially as the \"God particle\", the Higgs boson was theorized by Peter Higgs in 1964 as a solution to the mystery: why do particles have mass? The search ended in 2012 at CERN’s Large Hadron Collider, unraveling the particle by smashing protons at ludicrous speeds and scrutinizing the aftermath. The discovery was monumental, solidifying the Standard Model of physics and leading us to meticulously measure the decay characteristics of the Higgs boson, particularly into two tau particles, amidst the data chaos.\n",
    "\n",
    "## Kaggle Competitions: A Battlefield for Machine Learning Gladiators\n",
    "\n",
    "Remember when Netflix sparked a machine learning competition frenzy in 2006 with a \\$1 million prize? That was just the beginning! Kaggle became the arena where data scientists, from various realms, battled algorithms to solve problems, gaining insights and prizes along the way. The Higgs Boson Machine Learning Challenge was announced in 2014, [see here](https://www.kaggle.com/c/higgs-boson), drawing 1,875 teams into the fray with a $13,000 prize pool.\n",
    "\n",
    "## Enter the Dragon: XGBoost\n",
    "\n",
    "XGBoost, launched just 6 months before the Higgs challenge, became a sensation, propelling competitors up the Kaggle leaderboard while being a paragon of computational efficiency.\n",
    "\n",
    "## A Peek into the Data\n",
    "\n",
    "We're not using Kaggle's dataset, but the original from CERN’s open data portal, accessible [here](http://opendata.cern.ch/record/328). A bit larger than Kaggle’s, we'll stick to the first 250,000 rows and tweak it to mimic Kaggle's data. Fetch the dataset directly from [this GitHub repository](https://github.com/PacktPublishing/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/tree/master/Chapter05) and let's delve into it, keeping in mind it's a `.csv.gz` file, so we'll use `compression=gzip` when reading it into a pandas DataFrame.\n",
    "\n",
    "---\n",
    "\n",
    "And thus begins our exploration, where we fuse physics and machine learning, uncovering the stories data can tell us about the subatomic world with XGBoost as our guide!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6bb1b8ac-b54b-40a1-b4fa-1ebb75b1aa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from helper_file import *\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "594939e2-fc00-4300-816b-78322a4074f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"data/atlas-higgs-challenge-2014-v2.csv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31de0c32-aad0-417a-a26b-c9dbb53fc10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['EventId', 'DER_mass_MMC', 'DER_mass_transverse_met_lep',\n",
       "       'DER_mass_vis', 'DER_pt_h', 'DER_deltaeta_jet_jet', 'DER_mass_jet_jet',\n",
       "       'DER_prodeta_jet_jet', 'DER_deltar_tau_lep', 'DER_pt_tot', 'DER_sum_pt',\n",
       "       'DER_pt_ratio_lep_tau', 'DER_met_phi_centrality',\n",
       "       'DER_lep_eta_centrality', 'PRI_tau_pt', 'PRI_tau_eta', 'PRI_tau_phi',\n",
       "       'PRI_lep_pt', 'PRI_lep_eta', 'PRI_lep_phi', 'PRI_met', 'PRI_met_phi',\n",
       "       'PRI_met_sumet', 'PRI_jet_num', 'PRI_jet_leading_pt',\n",
       "       'PRI_jet_leading_eta', 'PRI_jet_leading_phi', 'PRI_jet_subleading_pt',\n",
       "       'PRI_jet_subleading_eta', 'PRI_jet_subleading_phi', 'PRI_jet_all_pt',\n",
       "       'Weight', 'Label', 'KaggleSet', 'KaggleWeight'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(url, \n",
    "                 nrows=250000, compression='gzip'\n",
    "                ).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6232aa-ce18-4eae-afc2-4c067218bcab",
   "metadata": {},
   "source": [
    "To match the Kaggle training data, let's delete the Kaggleset and Weight columns, convert KaggleWeight into 'Weight', and move the 'Label' column to the last column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a48840a2-8b8c-4b76-b3e5-8592d11d5237",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    pd.read_csv(url, nrows=250000, compression='gzip')\n",
    "    .drop(columns=['Weight', 'KaggleSet'])\n",
    "    .rename(columns={\"KaggleWeight\": \"Weight\"})\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b34f7e1-697a-4375-81e7-90642c1af354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['EventId', 'DER_mass_MMC', 'DER_mass_transverse_met_lep',\n",
       "       'DER_mass_vis', 'DER_pt_h', 'DER_deltaeta_jet_jet', 'DER_mass_jet_jet',\n",
       "       'DER_prodeta_jet_jet', 'DER_deltar_tau_lep', 'DER_pt_tot', 'DER_sum_pt',\n",
       "       'DER_pt_ratio_lep_tau', 'DER_met_phi_centrality',\n",
       "       'DER_lep_eta_centrality', 'PRI_tau_pt', 'PRI_tau_eta', 'PRI_tau_phi',\n",
       "       'PRI_lep_pt', 'PRI_lep_eta', 'PRI_lep_phi', 'PRI_met', 'PRI_met_phi',\n",
       "       'PRI_met_sumet', 'PRI_jet_num', 'PRI_jet_leading_pt',\n",
       "       'PRI_jet_leading_eta', 'PRI_jet_leading_phi', 'PRI_jet_subleading_pt',\n",
       "       'PRI_jet_subleading_eta', 'PRI_jet_subleading_phi', 'PRI_jet_all_pt',\n",
       "       'Label', 'Weight'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1728dd24-b41a-41cd-ab44-9913edadd372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250000 entries, 0 to 249999\n",
      "Data columns (total 33 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   EventId                      250000 non-null  int64  \n",
      " 1   DER_mass_MMC                 250000 non-null  float64\n",
      " 2   DER_mass_transverse_met_lep  250000 non-null  float64\n",
      " 3   DER_mass_vis                 250000 non-null  float64\n",
      " 4   DER_pt_h                     250000 non-null  float64\n",
      " 5   DER_deltaeta_jet_jet         250000 non-null  float64\n",
      " 6   DER_mass_jet_jet             250000 non-null  float64\n",
      " 7   DER_prodeta_jet_jet          250000 non-null  float64\n",
      " 8   DER_deltar_tau_lep           250000 non-null  float64\n",
      " 9   DER_pt_tot                   250000 non-null  float64\n",
      " 10  DER_sum_pt                   250000 non-null  float64\n",
      " 11  DER_pt_ratio_lep_tau         250000 non-null  float64\n",
      " 12  DER_met_phi_centrality       250000 non-null  float64\n",
      " 13  DER_lep_eta_centrality       250000 non-null  float64\n",
      " 14  PRI_tau_pt                   250000 non-null  float64\n",
      " 15  PRI_tau_eta                  250000 non-null  float64\n",
      " 16  PRI_tau_phi                  250000 non-null  float64\n",
      " 17  PRI_lep_pt                   250000 non-null  float64\n",
      " 18  PRI_lep_eta                  250000 non-null  float64\n",
      " 19  PRI_lep_phi                  250000 non-null  float64\n",
      " 20  PRI_met                      250000 non-null  float64\n",
      " 21  PRI_met_phi                  250000 non-null  float64\n",
      " 22  PRI_met_sumet                250000 non-null  float64\n",
      " 23  PRI_jet_num                  250000 non-null  int64  \n",
      " 24  PRI_jet_leading_pt           250000 non-null  float64\n",
      " 25  PRI_jet_leading_eta          250000 non-null  float64\n",
      " 26  PRI_jet_leading_phi          250000 non-null  float64\n",
      " 27  PRI_jet_subleading_pt        250000 non-null  float64\n",
      " 28  PRI_jet_subleading_eta       250000 non-null  float64\n",
      " 29  PRI_jet_subleading_phi       250000 non-null  float64\n",
      " 30  PRI_jet_all_pt               250000 non-null  float64\n",
      " 31  Label                        250000 non-null  object \n",
      " 32  Weight                       250000 non-null  float64\n",
      "dtypes: float64(30), int64(2), object(1)\n",
      "memory usage: 62.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079f8546-b2f3-4615-8af2-f3065e4af125",
   "metadata": {},
   "source": [
    "# A Quick Look at Our Data Columns\n",
    "\n",
    "Alright, let's take a swift tour through the columns of our data!\n",
    "\n",
    "### Column 0: `EventId`\n",
    "- **What's this?** Simply an identifier for each event. \n",
    "- **Use in Modeling?** Nope, our model doesn’t need this one.\n",
    "\n",
    "### Columns 1-30: Physics Features\n",
    "- **What's inside?** Various properties from LHC collisions.\n",
    "- **Special Note:** To get a deeper dive into what each of these columns represents, check out the [technical documentation](http://higgsml.lal.in2p3.fr/documentation). \n",
    "- **Use in Modeling?** Absolutely, these are the predictors for our model.\n",
    "\n",
    "### Column 31: `Weight`\n",
    "- **What's its role?** It scales the data. Given the rarity of Higgs boson events, weights help manage the imbalance and ensure our model doesn’t overlook them.\n",
    "- **A Caveat:** Weights aren't available in the test data, but we’ll discuss strategies on handling this in later chapters.\n",
    "\n",
    "### Column 32: `Label`\n",
    "- **What does it tell us?** Whether an event is a signal (`s`) or background (`b`). \n",
    "- **A Little Context:** The training data, though simulated from real data, has more signals than you’d typically find to aid learning about Higgs boson decay.\n",
    "- **Use in Modeling?** Yes, this one's our target variable.\n",
    "\n",
    "And there we have it! A straightforward overview of our data columns, ready to guide us as we dive into model building!\n",
    "\n",
    "We need to chamge the `Label` column into numerical format by replacing `s` values with 1 and `b` values with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79584864-b3f7-4999-91e6-e316f425188f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         s\n",
       "1         b\n",
       "2         b\n",
       "3         b\n",
       "4         b\n",
       "         ..\n",
       "249995    b\n",
       "249996    b\n",
       "249997    s\n",
       "249998    b\n",
       "249999    b\n",
       "Name: Label, Length: 250000, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0de5803a-bead-46bd-a207-1ee672af7fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    pd.read_csv(url, nrows=250000, compression='gzip')\n",
    "    # Drop unwanted columns\n",
    "    .drop(columns=['Weight', 'KaggleSet'])\n",
    "    # Rename column for clarity\n",
    "    .rename(columns={\"KaggleWeight\": \"Weight\"})\n",
    "    # Replace 's' and 'b' in 'Label' with 1 and 0, respectively\n",
    "    .assign(Label=lambda x: x['Label'].replace(('s', 'b'), (1, 0)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7067c1b8-b19b-4bb8-80c7-3a3e674e8f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of target vector: (250000,)\n",
      "shape of feature matrix: (250000, 32)\n"
     ]
    }
   ],
   "source": [
    "X, y = splitX_y(df, 'Label')\n",
    "\n",
    "print(f\"shape of target vector: {y.shape}\")\n",
    "print(f\"shape of feature matrix: {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdfc241-1ea6-45d4-82f3-5701285a1ed1",
   "metadata": {},
   "source": [
    "### A Simplified Guide to Scoring and Weights in the Higgs Challenge\n",
    "\n",
    "##### The Unique Scoring: Approximate Median Significance (AMS)\n",
    "- **What's Different?** The Higgs Challenge dances to its own tune - especially when it comes to scoring. It doesn't just look for accuracy but emphasizes the AMS. \n",
    "- **Defining AMS:** It’s a specific formula (detailed in the [technical documentation](http://higgsml.lal.in2p3.fr/documentation)) that values true positives and penalizes false negatives, with a regularization term of 10.\n",
    "- **Good News:** No need to manually define AMS - XGBoost has got our back here!\n",
    "\n",
    "##### A Quick Dive into Weights\n",
    "- **Why Weights?** Because in the real world, signals are a needle in the haystack of background noise. We use weights to adjust our model’s sensitivity to this.\n",
    "- **Using Weights:** Assign a higher weight to rare signals and a lower weight to common background noise. This ensures that our model doesn’t just predict everything as background!\n",
    "- **Practical Usage:** The weight column must reflect reality (the expected number of signal and background events). It’s crafted and scaled to match the expectations from our test data.\n",
    "\n",
    "###### Crafting the Weights: A Tiny How-to\n",
    "1. **Scaling Weights:** Adjust weights to match the size of our test data.\n",
    "   ```python\n",
    "   df['test_Weight'] = df['Weight'] * 550000 / len(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "651e732a-4bfe-4d51-ad8c-f2a486304d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    pd.read_csv(url, nrows=250000, compression='gzip')\n",
    "    .drop(columns=['Weight', 'KaggleSet'])\n",
    "    .rename(columns={\"KaggleWeight\": \"Weight\"})\n",
    "    .assign(\n",
    "        Label=lambda x: x['Label'].replace(('s', 'b'), (1, 0)),\n",
    "        test_Weight=lambda x: x['Weight'] * 550000 / len(x)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64125dba-8c51-43c4-8477-8932b1db0f8d",
   "metadata": {},
   "source": [
    "**Calculating Scale Factor**: A number derived from the sum of background weights divided by the sum of signal weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c94f407e-4104-49d4-aaed-0b762a8bd902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "593.9401931492318"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = np.sum(df[df['Label']==1]['test_Weight'])\n",
    "\n",
    "b = np.sum(df[df['Label']==0]['test_Weight'])\n",
    "\n",
    "b/s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c8b678-6507-47a1-9c46-185817c87051",
   "metadata": {},
   "source": [
    "#### More on Weights\n",
    "- To delve deeper into the world of weights, explore [this KDnuggets article](https://www.kdnuggets.com/2019/11/machine-learning-what-why-how-weighting.html).\n",
    "\n",
    "##### Building The Model: A Throwback to Original XGBoost API\n",
    "- **Old School API:** Back during the Higgs Challenge, everyone used the original XGBoost API (pre-scikit-learn).\n",
    "- **Why Mentioning This?** Because you’ll probably bump into it online, and it’s what was used in the Higgs Challenge.\n",
    "- **Our Approach:** We'll stick with this original API just for this chapter to keep things authentic.\n",
    "\n",
    "**And there we go!** A brief, uncomplicated guide to scoring and weights in the context of the Higgs Challenge, aiming to keep things as straightforward and clear as possible!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "411303b9-4b9a-450a-9139-4f5645a6ce6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xgb_clf = xgb.DMatrix(X, y, \n",
    "                      missing=-999.0, \n",
    "                      weight=df['test_Weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "acec58c5-0540-4a4a-bd53-a59119c97b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {}\n",
    "param['objective'] = 'binary:logitraw'\n",
    "param['scale_pos_weight'] = b/s\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 6\n",
    "param['eval_metric'] = 'auc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3405ef9-cae0-4229-a50d-d2b288969798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data end, start to boost trees\n",
      "[0]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[1]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[2]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[3]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[4]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[5]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[6]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[7]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[8]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[9]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[10]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[11]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[12]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[13]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[14]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[15]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[16]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[17]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[18]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[19]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[20]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[21]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[22]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[23]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[24]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[25]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[26]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[27]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[28]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[29]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[30]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[31]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[32]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[33]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[34]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[35]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[36]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[37]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[38]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[39]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[40]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[41]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[42]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[43]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[44]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[45]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[46]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[47]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[48]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[49]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[50]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[51]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[52]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[53]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[54]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[55]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[56]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[57]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[58]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[59]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[60]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[61]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[62]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[63]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[64]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[65]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[66]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[67]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[68]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[69]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[70]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[71]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[72]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[73]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[74]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[75]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[76]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[77]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[78]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[79]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[80]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[81]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[82]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[83]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[84]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[85]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[86]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[87]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[88]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[89]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[90]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[91]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[92]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[93]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[94]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[95]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[96]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[97]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[98]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[99]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[100]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[101]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[102]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[103]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[104]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[105]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[106]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[107]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[108]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[109]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[110]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[111]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[112]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[113]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[114]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[115]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[116]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[117]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[118]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "[119]\ttrain-auc:1.00000\ttrain-ams@0.15:66.38881\n",
      "finished training\n"
     ]
    }
   ],
   "source": [
    "plst = list(param.items())+[('eval_metric', 'ams@0.15')]\n",
    "watchlist = [(xgb_clf, 'train')]\n",
    "num_round = 120\n",
    "\n",
    "print('loading data end, start to boost trees')\n",
    "\n",
    "bst = xgb.train(plst, xgb_clf, num_round, watchlist)\n",
    "\n",
    "bst.save_model('higgs.model')\n",
    "\n",
    "print('finished training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcbb1f5-08ea-4bf0-a776-7986774b119e",
   "metadata": {},
   "source": [
    "```python\n",
    "plst = list(param.items())+[('eval_metric', 'ams@0.15')]\n",
    "```\n",
    "\n",
    "This line is crafting a list, `plst`, intended to configure parameters for training our XGBoost model. Let's dissect it:\n",
    "\n",
    "- `param.items()`: Extracts key-value pairs from the `param` dictionary, presenting them as tuples within a list.\n",
    "  \n",
    "- `[('eval_metric', 'ams@0.15')]`: A list housing a single tuple, where `'eval_metric'` is the parameter identifier and `'ams@0.15'` is its assigned value. Here, `ams` refers to Approximate Median Significance, a metric utilized in the Higgs Boson Kaggle Competition, with `0.15` acting as a threshold in AMS computation.\n",
    "\n",
    "- `list(param.items())+[('eval_metric', 'ams@0.15')]`: Merges the key-value pairs from `param` and the additional `eval_metric` parameter into one unified list, subsequently stored in `plst`.\n",
    "\n",
    "\n",
    "In the realm of the Higgs Boson Kaggle Competition, XGBoost didn’t just make an appearance; it shone brightly and was wielded effectively by competitors, particularly the victor, Gabor Melis. The baseline model for this competition, provided by Tianqi Chen, offered a solid foundation upon which Melis sculpted his winning model. \n",
    "\n",
    "You might wonder - what set Melis apart? Dive into his solution [here](https://github.com/melisgl/higgsml), and you'll note that while his tweaks to the baseline model weren’t groundbreaking, they were tactical and effective. A noteworthy strategy he employed was feature engineering, subtly crafting additional columns to enrich the data, a tactic we’ll explore more in Chapter 9.\n",
    "\n",
    "If you're intrigued by the prospect of crafting and submitting your own model to Kaggle post-competition, it's entirely possible! However, bear in mind that Kaggle submissions have their own set of nuances - they need to be ranked, correctly indexed, and submitted through the Kaggle API. A deeper dive into this is warranted for true mastery. A peek at the XGBoost ranking code [here](https://github.com/dmlc/xgboost/blob/master/demo/kaggle-higgs/higgs-pred.py) might offer some insights for those eager to embark on this journey.\n",
    "\n",
    "In essence, this episode of Kaggle competition showcased the might of XGBoost and the nuanced art of model tweaking and feature engineering, pivotal in propelling competitors towards victory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff72e54-a35c-4452-9312-8d212253df8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
